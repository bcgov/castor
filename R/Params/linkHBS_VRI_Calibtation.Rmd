---
title: "Estimating volume yield uncertainty from a meta-model of VDYP"
output: 
  html_document: 
    keep_md: yes
---

<!--
Copyright 2018 Province of British Columbia
 
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
 
http://www.apache.org/licenses/LICENSE-2.0
 
Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and limitations under the License.-->


# Introduction

Accurate estimates of timber volume are an important impetus for forestry decision making. Since the impacts of forestry decisions lie in the future and across vast areas, estimates of timber volume projected through time and across landscapes are of great interest for assessing the sustainability of these decisions. The economic value of timber and many ecological processes of interest to decision makers (e.g., biomass, carbon, wildlife habitat) are all driven by projections of forest structure which are often characterized by timber volume. Thus, a common concern by forestry decision makers is the level of uncertainty behind these projections across large landscapes. 

Often empirical growth and yield models are used to project timber volume through time because of their simplicity and ability to link to forest inventories and forecast entire landscapes. For large forested areas like the province of British Columbia, available stand-level forest attributes information supports the use of stand level growth and yield models. At a minimum the information required to parameterize these models includes: specific geographical or ecological zone, species compositions, a measure of site productivity (e.g., site index), the stands vertical (e.g., height) and horizontal (e.g., crown closure,trees per ha or basal area per ha) structure. This information is typically measured in a forest inventory which may have a high level of precision given the accuracy of the measured attributes which canbe challenging for generating timber volume projections across many landscapes. 

In the [Vegetation Resources Inventory](https://www.for.gov.bc.ca/hfd/library/documents/bib106996.pdf) (VRI) of British Columbia (BC), many of the stand attributes information needed to link to a growth and yield model are highly precise. Forest attributes like site index are reported to the nearest decimeter, species compositions can contain up to 6 species with an estimate of the percentage for each species to the nearest 1%, stand height is reported to the nearest decimeter and basal area to the nearest squared meter. Thus, the combinations of these highly precise input parameters would result in the generation of tens of millions of possible timber yield projections that consume valuable computer resources.

One approach to alleviate this problem is to aggregate the timber yield projections into groups (also termmed analysis units). A certain level of aggregation may be warranted, given the accuracy of forest inventory  may not support such a high level of precision. The [current standard](https://www2.gov.bc.ca/assets/gov/environment/natural-resource-stewardship/nr-laws-policy/risc/vri_photo_interp_qa_proc_and_stds_v43_2019.pdf) for quality assurance of VRI variables varies by attribute with species compositions around 80% correspondance, height $\pm$ 3 - 4 m,  age $\pm$ 10 years, crown closure $\pm$ 10%, basal area $\pm$ 10-15 $m^2$, trees per ha (tph) $\pm$ 100 stems. However, aggregation of yield curves results in a loss of information which may lead to incorrect decision making at the stand-level and results in a further source of unceratinty for decision makers. 

Clearly, there are many sources of uncertainty in timber volume projections. These sources propagate through time in complex ways which may provide barriers for confidentaly making forest management decisions. Recently, Robinson et al. (2016) recommended a simple way to incorpate this uncertainty into forestry decision making. Thier approach used observed timber volumes measured from scaling and cruising operations following harvesting. In particular, they propose a calibration model to not only calibrate yields but also to provide a measure of error around the volume estimate. Thus, the value of the Robinson et al. (2016) approach is two fold: i.) a calibration of the future timber volumes for use when simulating the forestry decisions and ii.) the ability to simulate the uncertainty in timber volume and thus calculate error statistics useful to decision makers. Robinson et al. (2016) modelled the parameters of the error distribution (conditional mean and variance) for a given prediction. These parameters were then used to reconstruct the error distribution for any prediction. For many harvest blocks these distributions were then sampled many times (i.e., 10000) and then summed to arrive at a total distribution of plausible timber volumes (assuming indepednance). 

Currently, this approach has not been applied in the province of BC given issues with tracking observed scaled volumes. The tracking of observed scaled volume is accomplished by the harvest billing system (HBS) which provides observed billable harvest volumes needed for provincal revenue accounting at a spatial unit known as a timber mark. The timber mark is a unique identifer stamped or marked on the end of each log to associate the log with the specific authority to harvest and move timber. Timber marks are assigned to harvested units that may be not be spatially contiguous nor contain a single harvest date. Thus, linking HBS and forest inventory data has been difficult due to issues with temporal and spatial accuracy in estimating the spatial boundaries of the timber marks. In particular, estimating the net area harvested (i.e., netting out roads, wildlife tree patches, etc) and its spatial boundary can be difficult to determine for historical cutblocks.

In the following sections, I attempt to link the HBS with the provincial forest inventory. The spatial (timber mark boundaries) and temporal (harvest date, inventory projection) data are manipulated to follow the approach by Robinson et al. (2016) in BC. The specific objectives are: i) to calibrate the projected volume yields from an aggregated growth and yield model (hereafter termed the meta-model) with observed volume yields reported in the harvest billing system and ii) demonstrate the use of this model in landscape simulations for assessing error in yields. The proposed calibration model will be used in the caribou and landuse model (CLUS) to provide an indication of volume yield uncertainty which will help provide some context surrounding the quantification of impacts from caribou conservation activities on harvest flows. 

# Methods
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(sf)
library(dplyr)
library(velox)
library(ggplot2)
library(Hmisc)
library(bcmaps)
library(gstat)
library(ape)
library(ade4)
library(plotly)
library(gamlss)
library(cowplot)
source("C:/Users/KLOCHHEA/clus/R/functions/R_Postgres.R")
```

## Linking timber mark boundaries with VRI

To link the timber mark boundaries with the VRI (needed to link to a growth and yield model) the following steps were completed (see [code](https://github.com/bcgov/clus/blob/master/SQL/develop_vri2011table.sql))

1. Estimate the spatial boundaries of the timber marks

The spatial boundaries of the timber mark were estimated using the compilation of two spatial data sets: i) [forest tenure cutblock polygons](https://catalogue.data.gov.bc.ca/dataset/forest-tenure-cutblock-polygons-fta-4-0) (aka. ftn_c_b_pl_polygon) and ii) [consolidated cutblock polygons](https://catalogue.data.gov.bc.ca/dataset/harvested-areas-of-bc-consolidated-cutblocks-) (a.k.a cns_cut_bl_polygon). Using the forest tenure cutblock polygons, all timber marks comprised of openings (harvest units) that had disturbance start dates between 2012-01-01 and 2016-12-31 were selected (i.e., removed possible timber marks with some openings not in this range). This selected subset of forest tenure cutblock polygons was then joined with consolidated cutblock polygons by the harvest unit identifier (viz. opening_id). This join provided the link between the timber mark and its spatial geometry of the harvesting boundary. Lastly, timber marks were removed if they did not fully contain geometries reported by RESULTS (the most accurate form of reporting cutblock information). This ensured a more accurate net spatial description of the timber mark boundary (i.e., retention patches were removed). Despite the accuracy of the RESULTS, there remain a number of issues with identifying retention patches which resulted in the consolidated cutblock polygons data missing portions of the harvest unit. Thus, timber marks were removed when the estimated timber mark area was not with $/pm$ 20% of the planned net area. The result of this process was 1941 unique timber marks.

2. Intersect the timber mark spatial boundaries with the VRI

The resulting timber mark spatial boundaries were spatialy intersected with the 2011 VRI to provide the necessary forest attribute information for linking to the growth and yield model. Only the dominant layer (layer rank 1) of the forest invetnory was used to link to the growth and yield model. As a result of this intersection, 1264 of the timber marks had a portion of their total area that failed to provide the neccessary forest inventory information (i.e., areas that lack the publically available forest inventory such as Tree Farm Licenses). 

The following is a histogram of the percentage of the total timber mark area without the required inventory information:

```{r, timber_mrks, echo = FALSE, fig.cap = 'FIGURE 1. A histogram of the percentage of the total timber mark area that did not match with forested VRI polygons. q25 and q75 are the 25th and 75th quantile, respectively.'}
feats<-getSpatialQuery("SELECT feature_id, shape, yc_grp, bec_zone_code, site_index, crown_closure, pcnt_dead, proj_height_1, proj_age_1 FROM yt_vri2011")
#cnx_hbs<-getSpatialQuery("SELECT * FROM cnx_hbs")

cnx_hbs<-getSpatialQuery("SELECT * FROM cnx_hbs where timber_mrk in (select timber_mrk from (
select count(*) as no_opens, foo.timber_mrk from (select count(*) as no_opening_id, opening_id, timber_mrk from cnx_hbs 
group by opening_id, timber_mrk order by timber_mrk) as foo
group by foo.timber_mrk) as foo2 where no_opens = 1)")

cnx_hbs<-lwgeom::st_make_valid(cnx_hbs)

polys<- st_intersection(cnx_hbs, feats) #spatialy join the timber mark boundaries with the id that links the VRI
polys$area<-st_area(polys)/10000 #calc the area of the individual polygons within a timber mark
polys$time_since_inv<-polys$harvestyr -2011
polys$age_hrv<-polys$proj_age_1 + polys$time_since_inv


#get elevation?
ras.elv<-getTableQuery("SELECT  timber_mrk, (stats).*
FROM (SELECT timber_mrk, ST_SummaryStats(ST_Clip(rast, feat.wkb_geometry)) As stats
      FROM rast.dem
      INNER JOIN  (SELECT timber_mrk, st_union(wkb_geometry) as wkb_geometry 
				   FROM cnx_hbs where timber_mrk in (select timber_mrk from (
select count(*) as no_opens, timber_mrk from (select count(*) as no_opening_id, opening_id, timber_mrk from cnx_hbs 
group by opening_id, timber_mrk order by timber_mrk) as foo
group by timber_mrk) as foo2 where no_opens = 1   ) group by timber_mrk
   ) as feat
    ON ST_Intersects(feat.wkb_geometry,rast) 
 ) As foo")
    
#Create a temp table?
conn<-GetPostgresConn()
dbWriteTable(conn, "polys",polys)
dbDisconnect(conn)

yt_prj<-getTableQuery("SELECT t.feature_id, t.yc_grp, t.bec_zone_code,
  (((k.prj_vol_dwb - y.prj_vol_dwb*1.0)/10)*(t.age_hrv - CAST(t.age_hrv/10 AS INT)*10))+ y.prj_vol_dwb as itvol
  FROM polys t
  LEFT JOIN vdyp_test3 y 
  ON t.yc_grp = y.yc_grp AND CAST(t.age_hrv/10 AS INT)*10 = y.prj_total_age
  LEFT JOIN vdyp_test3 k 
  ON t.yc_grp = k.yc_grp AND round(t.age_hrv/10+0.5)*10 = k.prj_total_age WHERE t.age_hrv > 0
  ;")

#delete the temp table
conn<-GetPostgresConn()
dbExecute(conn, "Drop table polys;")
dbDisconnect(conn)

#join with poly
out.tbl<-merge(polys, yt_prj)
out.tbl$vol<-out.tbl$area*out.tbl$itvol #calc the volumes for each of the individual polygons within a timber mark
#st_write(out.tbl, "test3.shp")

#get the itvols that are NULL == don't match with the meta-model
out.tbl2<-data.table(out.tbl)
units(out.tbl2$area) <- NULL
units(out.tbl2$vol) <- NULL

#43118
out.tbl2<-out.tbl2[!(timber_mrk == 'BY5H37'),] #this timber mark also has a missing portion but becuase its large this small portion was within +- 20%

test.1 <-data.table(out.tbl2)
number_obs<-test.1[, .(count = .N, var = sum(area)), by = timber_mrk ]

#figure out the distrubution of area with no matching
noMatchArea<-out.tbl2[is.na(itvol), sum(area), by =timber_mrk]
setnames(noMatchArea, "V1", "area")
totalArea<-out.tbl2[, sum(area), by =timber_mrk]
setnames(totalArea, "V1", "totarea")
percentNoMatch<-merge(noMatchArea, totalArea)
percentNoMatch$pernomatch<-percentNoMatch$area/percentNoMatch$totarea


#plot the distribution
eq <- substitute(italic(q25)== a*","~~italic(q75)== b ,list(a=as.numeric(quantile(percentNoMatch$pernomatch,0.25)), b= as.numeric(quantile(percentNoMatch$pernomatch,0.75))))
  
ggplot(data = data.table(per.Area.Missing=percentNoMatch$pernomatch), aes(x=per.Area.Missing)) +
  geom_histogram(bins =120)+
  geom_vline(xintercept=quantile(percentNoMatch$pernomatch,0.25))+
  geom_vline(xintercept=quantile(percentNoMatch$pernomatch,0.75))+
  geom_text(aes(x = 0.30, y =800 , label = as.character(as.expression(eq)) ), parse = TRUE) + 
  theme_bw()

```

This histogram suggests that 75% of timber marks that do not have the neccessary forest inventory attribution are missing this information for less than 2.4% of their total area. After visually checking, two issues arose: i) the spatial boundaries of these timber marks extend into non-forested area as reported by the VRI; and ii) there wasn't enough information to parameterize the growth and yield model (outside the domain of the inputs, e.g., recently disturbed). In the case of the non-forested areas, these could be wrongfully classified as determined in the VRI. From a practical view, these relatively small areas would result in little contribution to the total projected volume estimate. Thus, timber marks with less than or equal to 3 percent of their total area that contained inadequate forest inventory information were retained in the analysis.


```{r, sample, echo = FALSE, fig.cap = 'FIGURE 2. The location of timber marks used in the analysis (n = 1672).'}
noMatch2<-unique(percentNoMatch[pernomatch > 0.03, timber_mrk])
timbr_mrks<-out.tbl2[!(out.tbl2$timber_mrk %in% noMatch2),]
timbr_mrks[is.na(vol), vol:=0]
test.1 <-data.table(timbr_mrks)
number_obs<-test.1[, .(count = .N, var = sum(area)), by = timber_mrk ]

out.tbl3<-timbr_mrks[, sum(vol), by =timber_mrk]
setnames(out.tbl3, c("V1", "timber_mrk"), c("proj_vol","timber_mark"))

out.tbl3.area<-timbr_mrks[, sum(area), by =timber_mrk]
setnames(out.tbl3.area, c("V1", "timber_mrk"), c("area","timber_mark"))

out.tbl4<-merge(out.tbl3,out.tbl3.area)

hbs_obs<-getTableQuery("SELECT timber_mark, sum(volume_m3) as obs_vol FROM hbs_select_tmbr_mrk  where waste_type = 'Non-Waste' AND coast_interior = 'Interior' group by timber_mark")

dead_hbs_obs<-getTableQuery("SELECT distinct(timber_mark) FROM hbs_select_tmbr_mrk where grade = 'CB Dead'")
hbs_obs<-hbs_obs[!(hbs_obs$timber_mark %in% dead_hbs_obs$timber_mark),]

calb_data<-data.table(merge(hbs_obs, out.tbl4))
units(calb_data$area) <- NULL
units(calb_data$proj_vol) <- NULL

calb_data<-calb_data[proj_vol > 100 , ] # get rid of small blcoks that may not be some sort of alternative cutting system
calb_data<-calb_data[obs_vol > 100 , ] # get rid of small blcoks that may not be some sort of alternative cutting system

#check outliers
#'WAWVFF' ,'WBJKDD' , '88606', 'DE2270', '52/911', 'DE2621', 'EU6615'
#WAWVFF is a small triangle problem with mapping the area its 0.6 ha so very small remove
#WBJKDD is also less than 1 ha remove
#No reason to remove 88606 -- looks ok VRI reporting a site index of 10
#No reason to remove DE2270 -- looks ok VRI reporting a site index of 8
#52/911 area wrong remove
#No reason to remove - DE2621 -- VRI site index 10-12 (low)
# Nor reason to remove EU6615 -- VRI site index 8

calb_data<- calb_data[!(timber_mark %in% c('WAWVFF','WBJKDD', '52/911')),]
calb_data$proj_vol<-as.numeric(calb_data$proj_vol)

#Get the spatial X,Y coordinates
cents<-st_read(paste0(here::here(), "/R/Params/centroid_timber_mkrs2.shp"))
cents2<-st_coordinates(st_sf(cents))
cents2<-data.table(cents2)
cents2$timber_mark<-cents$tmbr_mr
calb_data<-merge(calb_data, cents2, by.x = "timber_mark", by.y ="timber_mark", all.x = TRUE)

#Get the elevation
ras.elv<-data.table(ras.elv)
setnames(ras.elv, "timber_mrk", "timber_mark")

ras.elv2<-ras.elv[, weighted.mean(mean, count), by =timber_mark]
ras.elv2[timber_mark == '90884', V1:= 1372]
calb_data<-merge(calb_data, ras.elv2, by.x ="timber_mark", by.y = "timber_mark", all.x = TRUE )
setnames(calb_data, "V1", "elv")
#map the observations?
#bec <-get_layer("bec")
#ggplot() + geom_sf(data = bec, aes(fill=ZONE), size =0.1)+ geom_point(data=calb_data, aes(x=MEAN_X, y=MEAN_Y), color="red")
```


## Growth and yield meta-model

Each polygon was projected through time to 350 years using [Variable Density Yield projection](https://www2.gov.bc.ca/gov/content/industry/forestry/managing-our-forest-resources/forest-inventory/growth-and-yield-modelling/variable-density-yield-projection-vdyp) (VDYP) with the VRI (2018 vintage). VDYP is a stand-level empirical growth and yield model that uses VRI attribution as inputs into its algortihums. The result of this process was a dataset with over 3.5 million yield curves which took 3 days to complete on a intel xeon, 3.5 ghz processor with 64 GB of RAM. Both the input (VRI information) and outputs (yields over time) were uploaded into a PostgreSQL database for further processing. Using the layer 1 rank information (the dominant layer),  yield curve groups (yc_grp) or anlaysis units were constructed using: BEC zone, site index (2 m interval), height class (5 classes as per the VRI) and crown closure class (5 classes as per the VRI). Each yc_grp was then aggregated by area weighting the respsective individual polygon level yield curves. The result was a provincial database of composite yield curves that directly link to the 2018 VRI through the layer 1 rank attribution described above.

## HBS volumes vs projected meta-model volumes

Each projected VRI polygon that intersected the timber mark boundary was summed to estimate the total projected volume for the timber mark.The HBS data was also aggregated by timber mark and matched with the projected volumes. The result is shown below that compares the projected volumes from the meta model with the observed volumes that were reported in the HBS. Timber marks with scaled dead wood were removed since the meta model of growth and yield did not estimate stand dead timber. The result was 768 timber marks.

```{r, echo = FALSE, Step6_develop_vri2011, fig.cap = 'FIGURE 3. The relationship between observed (obs_vol) and projected (proj_vol) volumes ($m^3$). The yellow line is a one to one relationship; the blue line is a linear line of best fit; the dashed red lines represent the 95% prediction interval (n= 1672).'}

model1 <- lm(obs_vol ~ proj_vol, data=calb_data)
summary(model1)
temp_var <- predict(model1, data =calb_data, interval="prediction")
calb_data2 <- cbind(calb_data, temp_var)

lm_eqn = function(m) {
  l <- list(a = format(as.numeric(coef(m)[1]), digits = 2),
      b = format(as.numeric(coef(m)[2]), digits = 2),
      r2 = format(summary(m)$r.squared, digits = 3))
  eq <- substitute(italic(y) == a + b %.% italic(x)*","~~italic(r)^2~"="~r2,l)
  as.character(as.expression(eq))                 
}

ggplot(calb_data2, aes(proj_vol, obs_vol)) +
  geom_point() +
  geom_smooth(method='lm', se = TRUE)+
  geom_line(aes(y=lwr), color = "red", linetype = "dashed")+
  geom_line(aes(y=upr), color = "red", linetype = "dashed") +
  geom_text(aes(x = 35000, y = 100000, label = lm_eqn(model1)), parse = TRUE) +
    geom_abline(intercept =0, slope=1, col ="yellow") +
  theme_bw()


```

### Histgram
```{r, dist_proj_vol, fig.cap="FIGURE 4. Histogram of the projected volumes of timber marks between 2012 to 2016 (n=2140)"}
 hist(calb_data2$obs_vol)
```


## Predictors of error

Following Robinson et al. (2016) the error between observed and projected volume yields was paritioned according to both forest quality class (high and low) and timber type (mature or mixedwood). This supported the conditional mean and variance to be modelled seperately for each of these factors. In this BC application, stand-level attribution was included to test hypotheses of which variables that could be important predictors of error between observed and projected yield volumes.

```{r, predictors}

# get the bec zone that makes up the majority of the timber mark 
pv_timber_mrk<-merge(timbr_mrks, totalArea)
pv_timber_mrk[,wt:=as.numeric(area/totarea)]
pv_timber_mrk2<-pv_timber_mrk[, lapply(.SD, function(x) {wtd.mean (x, wt)}), by =timber_mrk, .SDcols=c("proj_height_1", "site_index", "crown_closure", "proj_age_1", "pcnt_dead")]
setnames(pv_timber_mrk2, "timber_mrk" , "timber_mark" )
calb_data3<-merge(calb_data2, pv_timber_mrk2, by = "timber_mark")
calb_data3[, dif:=proj_vol-obs_vol]

cor.test(calb_data3$elv, calb_data3$dif)
cor.test(calb_data3$proj_height_1, calb_data3$dif)
cor.test(calb_data3$site_index, calb_data3$dif)
cor.test(calb_data3$crown_closure, calb_data3$dif)
cor.test(calb_data3$proj_age_1, calb_data3$dif)
cor.test(calb_data3$pcnt_dead, calb_data3$dif)

```


## The calibration model

In Robinson et al. (2016) a gamma model was used to model both the conditional mean and conditional variance of the error distribution. Gamma models are advantageous because they are highly flexible in the positive domain and allow the modeling of heteroskedastic variance. Below we try a few gamma models by incorporating forest attributes. This area could be greatly improved to try other distributions (e.g., Exponential, Beta) or other parameters (e.g., variance of stand attributes, number of years projected?, dead pine?, BEC zones?, etc) 

```{r, calibrate_model,  fig.cap= 'FIGURE 4. The calibration model inder different assumptions of the forest attributes. Blue line is the conditional mean, blue dotted lines are the 66% prediction intervals and the red dashed lines are the 90% prediction intervals (n=1672)' }

calb_data4<-na.omit(calb_data3)

## Fit and compare some models
test.0 <- gamlss(obs_vol ~ proj_vol,
                 sigma.formula = ~ 1,
                 mu.link = "log",
                 sigma.link = "log",
                 family = GA(),
                 data = calb_data4)

test.1 <- gamlss(obs_vol ~ log(proj_vol),
                 sigma.formula = ~ 1,
                 sigma.link = "log",
                 family = GA(),
                 data = calb_data4)

test.2 <- gamlss(obs_vol ~ log(proj_vol),
                 sigma.formula = ~ proj_vol,
                 sigma.link = "log",
                 family = GA(),
                 data = calb_data4)

test.3 <- gamlss(obs_vol ~ log(proj_vol),
                 sigma.formula = ~ log(proj_vol),
                 sigma.link = "log",
                 family = GA(),
                 data = calb_data4)

test.4 <- gamlss(obs_vol ~ log(proj_vol),
                 sigma.formula = ~ log(proj_vol) + proj_height_1,
                 sigma.link = "log",
                 family = GA(),
                 data = calb_data4)


LR.test(test.3, test.4)
chosen<-test.4
summary(chosen)
wp(chosen)
plot(chosen)
```


## Model plots
```{r, plot_some_stuff}
#res<-residuals(chosen)
#saveRDS(chosen, "calb_ymodel.rds")
#saveRDS(calb_data4, "calb_data.rds")

trajectory.l.l <-
  with(calb_data4,
       expand.grid(proj_vol =
                   seq(from = min(proj_vol),
                       to = max(proj_vol),
                       length.out = 100),
                   proj_height_1= min(proj_height_1),
                   proj_age_1= min(proj_age_1),
                   X = mean(X),
                   Y = mean(Y),
                   dummy = 1
                   ))

new.dist.l <- predictAll(chosen, newdata = trajectory.l.l)

trajectory.l.l$mu <- new.dist.l$mu
trajectory.l.l$sigma <- new.dist.l$sigma
trajectory.l.l$upper.2 <- with(new.dist.l, qGA(0.95, mu = mu, sigma = sigma))
trajectory.l.l$lower.2 <- with(new.dist.l, qGA(0.05, mu = mu, sigma = sigma))
trajectory.l.l$upper.1 <- with(new.dist.l, qGA(0.67, mu = mu, sigma = sigma))
trajectory.l.l$lower.1 <- with(new.dist.l, qGA(0.33, mu = mu, sigma = sigma))

trajectory.l.h <-
  with(calb_data4,
       expand.grid(proj_vol =
                   seq(from = min(proj_vol),
                       to = max(proj_vol),
                       length.out = 100),
                   proj_height_1= mean(proj_height_1),
                   proj_age_1= mean(proj_age_1),
                   X = mean(X),
                   Y = mean(Y),
                   dummy = 1
                   ))


new.dist.l <- predictAll(chosen, newdata = trajectory.l.h)

trajectory.l.h$mu <- new.dist.l$mu
trajectory.l.h$sigma <- new.dist.l$sigma
trajectory.l.h$upper.2 <- with(new.dist.l, qGA(0.95, mu = mu, sigma = sigma))
trajectory.l.h$lower.2 <- with(new.dist.l, qGA(0.05, mu = mu, sigma = sigma))
trajectory.l.h$upper.1 <- with(new.dist.l, qGA(0.67, mu = mu, sigma = sigma))
trajectory.l.h$lower.1 <- with(new.dist.l, qGA(0.33, mu = mu, sigma = sigma))

trajectory.h.l <-
  with(calb_data4,
       expand.grid(proj_vol =
                   seq(from = min(proj_vol),
                       to = max(proj_vol),
                       length.out = 100),
                   proj_height_1= quantile(proj_height_1, 0.5),
                   proj_age_1= quantile(proj_age_1, 0.5),
                   X = mean(X),
                   Y = mean(Y),
                   dummy = 1
                   ))

new.dist.h <- predictAll(chosen, newdata = trajectory.h.l)

trajectory.h.l$mu <- new.dist.h$mu
trajectory.h.l$sigma <- new.dist.h$sigma
trajectory.h.l$upper.2 <- with(new.dist.h, qGA(0.95, mu = mu, sigma = sigma))
trajectory.h.l$lower.2 <- with(new.dist.h, qGA(0.05, mu = mu, sigma = sigma))
trajectory.h.l$upper.1 <- with(new.dist.h, qGA(0.67, mu = mu, sigma = sigma))
trajectory.h.l$lower.1 <- with(new.dist.h, qGA(0.33, mu = mu, sigma = sigma))

trajectory.h.h <-
  with(calb_data4,
       expand.grid(proj_vol =
                   seq(from = min(proj_vol),
                       to = max(proj_vol),
                       length.out = 100),
                   proj_height_1= max(proj_height_1),
                   proj_age_1= max(proj_age_1),
                   X = mean(X),
                   Y = mean(Y),
                   dummy = 1
                   ))

new.dist.h <- predictAll(chosen, newdata = trajectory.h.h)

trajectory.h.h$mu <- new.dist.h$mu
trajectory.h.h$sigma <- new.dist.h$sigma
trajectory.h.h$upper.2 <- with(new.dist.h, qGA(0.95, mu = mu, sigma = sigma))
trajectory.h.h$lower.2 <- with(new.dist.h, qGA(0.05, mu = mu, sigma = sigma))
trajectory.h.h$upper.1 <- with(new.dist.h, qGA(0.67, mu = mu, sigma = sigma))
trajectory.h.h$lower.1 <- with(new.dist.h, qGA(0.33, mu = mu, sigma = sigma))

p.l.l <-
  ggplot(calb_data4, aes(x = proj_vol, y = obs_vol) ) +
  geom_point(alpha=0.4) +
  #facet_wrap(~ ForestQualityClass) +
  xlab(expression(paste("Projected Volume Yield ", m^3, ")"))) +
  ylab(expression(paste("Observed Volume Yield ", m^3, ")"))) +
  geom_line(aes(y = mu, x = proj_vol), color = 'blue', data = trajectory.l.l, lwd = 1.75) +
  geom_line(aes(y = lower.2, x =  proj_vol), linetype = "dashed", color = 'red', data = trajectory.l.l) +
  geom_line(aes(y = upper.2 , x =  proj_vol), linetype = "dashed", color = 'red', data = trajectory.l.l) +
  geom_line(aes(y = lower.1 , x =  proj_vol), linetype = "dotted", color = 'blue', data = trajectory.l.l) +
  geom_line(aes(y = upper.1 , x =  proj_vol), linetype = "dotted", color = 'blue', data = trajectory.l.l) +
  geom_abline(intercept =0, slope=1, col ="yellow")+
  ylim(0,200000)

p.l.h <-
  ggplot(calb_data4, aes(x = proj_vol, y = obs_vol) ) +
  geom_point(alpha=0.4) +
  #facet_wrap(~ ForestQualityClass) +
  xlab(expression(paste("Projected Volume Yield ", m^3, ")"))) +
  ylab(expression(paste("Observed Volume Yield ", m^3, ")"))) +
  geom_line(aes(y = mu, x = proj_vol), color = 'blue', data = trajectory.l.h, lwd = 1.75) +
  geom_line(aes(y = lower.2, x =  proj_vol), linetype = "dashed", color = 'red', data = trajectory.l.h) +
  geom_line(aes(y = upper.2 , x =  proj_vol), linetype = "dashed", color = 'red', data = trajectory.l.h) +
  geom_line(aes(y = lower.1 , x =  proj_vol), linetype = "dotted", color = 'blue', data = trajectory.l.h) +
  geom_line(aes(y = upper.1 , x =  proj_vol), linetype = "dotted", color = 'blue', data = trajectory.l.h) +
  geom_abline(intercept =0, slope=1, col ="yellow")+
  ylim(0,200000)

p.h.l <-
  ggplot(calb_data4, aes(x = proj_vol, y = obs_vol) ) +
  geom_point(alpha=0.4) +
  #facet_wrap(~ ForestQualityClass) +
  xlab(expression(paste("Projected Volume Yield (", m^3, ")"))) +
  ylab(expression(paste("Observed Volume Yield (", m^3, ")"))) +
  geom_line(aes(y = mu, x = proj_vol), color = 'blue', data = trajectory.h.l, lwd = 1.75) +
  geom_line(aes(y = lower.2, x =  proj_vol), linetype = "dashed", color = 'red', data = trajectory.h.l) +
  geom_line(aes(y = upper.2 , x =  proj_vol), linetype = "dashed", color = 'red', data = trajectory.h.l) +
  geom_line(aes(y = lower.1 , x =  proj_vol), linetype = "dotted", color = 'blue', data = trajectory.h.l) +
  geom_line(aes(y = upper.1 , x =  proj_vol), linetype = "dotted", color = 'blue', data = trajectory.h.l) +
  geom_abline(intercept =0, slope=1, col ="yellow")+
  ylim(0,200000)

p.h.h <-
  ggplot(calb_data4, aes(x = proj_vol, y = obs_vol) ) +
  geom_point(alpha=0.4) +
  #facet_wrap(~ ForestQualityClass) +
  xlab(expression(paste("Projected Volume Yield (", m^3, ")"))) +
  ylab(expression(paste("Observed Volume Yield (", m^3, ")"))) +
  geom_line(aes(y = mu, x = proj_vol), color = 'blue', data = trajectory.h.h, lwd = 1.75) +
  geom_line(aes(y = lower.2, x =  proj_vol), linetype = "dashed", color = 'red', data = trajectory.h.h) +
  geom_line(aes(y = upper.2 , x =  proj_vol), linetype = "dashed", color = 'red', data = trajectory.h.h) +
  geom_line(aes(y = lower.1 , x =  proj_vol), linetype = "dotted", color = 'blue', data = trajectory.h.h) +
  geom_line(aes(y = upper.1 , x =  proj_vol), linetype = "dotted", color = 'blue', data = trajectory.h.h) +
  geom_abline(intercept =0, slope=1, col ="yellow")+
  ylim(0,200000)

plot_grid(p.l.l, p.h.l,p.l.h, p.h.h, labels = c("min(ht)", "mean(ht)","median(ht)", "max(ht)"))

```


## Autocorrelation

A caveat of the uncertainty model is that the errors are independant - in order to be able to sum across many predictions and achieve the appropriate total. Here I test for autocorrelation in the residuals.

```{r, testing_auto_correlation}

ind.1<- predictAll(chosen, newdata = calb_data4)
ind.2<-cbind(calb_data4, ind.1$mu)
ind.2$res<-ind.2$obs_vol - ind.2$V2

#get distances
dists <- as.matrix(dist(cbind(auto.2$X, auto.2$Y)))
dists.inv <- 1/dists 
diag(dists.inv) <- 0
#dists[1:50, 1:50] # check what they look like - units are in metres

#auto.2$res<-auto.2$res+runif(326, 1, 10000)
Moran.I(ind.2$res, dists.inv)
#observed is significantly greater than expected  - positively correlated. Thus, jointly contribute more to the uncertainty then their sum would suggest.

xyspatial=SpatialPoints(cbind(ind.2$X,ind.2$Y))
porspatial=data.frame(ind.2$res)
spatialdata=SpatialPointsDataFrame(xyspatial,porspatial)

vario2 <- variogram(ind.2$res~1, spatialdata, cutoff = 2500)
plot(vario2)
bubble(spatialdata, "ind.2.res", col = c("blue", "orange"), main = "Residuals", xlab = "X-coordinates", 
    ylab = "Y-coordinates")


```


## Autocorrelated model

To account for the autocorrelation in the model we construct a random effect with mean zero and covariance structure modelled using the spatial lage between observations. Thus the off diagonal elements of the variance-covariance matrix will be estiamted using a spatial covariance structure that is parameterized from model assuming independance. 

```{r, autocorr}
calb_data4$dummy<-1
chosen.a <- gamlss(obs_vol ~log(proj_vol) + re(random=~1|dummy, correlation = corSpher(2000, form = ~ X + Y, nugget = T), opt="optim"),
                   sigma.formula = ~ log(proj_vol) + proj_height_1,
                   sigma.link = "log",
                   family = GA(), data = calb_data4, control = gamlss.control(c.crit = 0.005), method=CG())

plot(chosen.a)

auto.1<- predictAll(chosen.a, newdata = calb_data4)
auto.2<-cbind(calb_data4, auto.1$mu)
auto.2$res<-auto.2$obs_vol - auto.2$V2

Moran.I(auto.2$res, dists.inv)
#There is more evidence for the null hypothesis

xyspatial.auto=SpatialPoints(cbind(auto.2$X,auto.2$Y))
porspatial.auto=data.frame(auto.2$res)
spatialdata.auto=SpatialPointsDataFrame(xyspatial.auto,porspatial.auto)
vario2 <- variogram(auto.2$res~1, spatialdata, cutoff = 2500)
plot(vario2)

#look at the residuals -- less clustering going on
par(mfrow = c(2,1))
bubble(spatialdata.auto, "auto.2.res", col = c("blue", "orange"), main = "Residuals", xlab = "X-coordinates", 
    ylab = "Y-coordinates")
bubble(spatialdata, "ind.2.res", col = c("blue", "orange"), main = "Residuals", xlab = "X-coordinates", 
    ylab = "Y-coordinates")

#See how the coefficents change. Note the significance on the intercept. Intercept significance is different.
chosen.a$mu.coefSmo
summary(chosen.a)
summary(chosen)

#Note the AIC is much smaller than the model assuming independance
AIC(chosen.a)
AIC(chosen)

#The likelihood ratio test doesn't suggest change
LR.test(chosen.a, chosen)

#Much residuals slightly larger with autocorrelated model -- more uncertainty that the indepdnant more would suggest
sum(auto.2$res**2)-sum(ind.2$res**2)



```

Observations
* Larger projected volumes inherantly have more variation in acheiving the actual volumes. 

* The variation around the calibration model is negatively affected by VRI projected height

#### Summing iid GA random variables -- rather than simulating via monte carlo

```{r, iid}
#Assuming indepdnance model
test.iid.data<-ind.2[,c("obs_vol", "proj_vol", "X", "Y", "proj_age_1", "proj_height_1")] 
test.iid.0<- predictAll(chosen, newdata = test.iid.data) 
test.iid.data$mu<-test.iid.0$mu 
test.iid.data$sigma<-test.iid.0$sigma 
  
sum(test.iid.data$obs_vol)
sum(test.iid.data$proj_vol)
sum(test.iid.data$mu)
sqrt(sum((test.iid.data$mu*test.iid.data$sigma)**2))

#est param
sqrt(sum((test.iid.data$mu*test.iid.data$sigma)**2))/sum(test.iid.data$mu)
summed<-rGA(20000, mu = sum(test.iid.data$mu), sigma = sqrt(sum((test.iid.data$mu*test.iid.data$sigma)**2))/sum(test.iid.data$mu) )
hist(summed)
quantile(summed, c(0.05, 0.5, 0.95))

#-------
#Autocorrelated model
test.auto.data<-auto.2[,c("obs_vol", "proj_vol", "X", "Y", "proj_age_1", "proj_height_1", "dummy")] 
test.auto.0<- predictAll(chosen.a, newdata = test.auto.data) 
test.auto.data$mu<-test.auto.0$mu 
test.auto.data$sigma<-test.auto.0$sigma 
  
sum(test.auto.data$obs_vol)
sum(test.auto.data$proj_vol)
sum(test.auto.data$mu)
sqrt(sum((test.auto.data$mu*test.auto.data$sigma)**2))

#est param
sqrt(sum((test.auto.data$mu*test.auto.data$sigma)**2))/sum(test.auto.data$mu)
summed.auto<-rGA(20000, mu = sum(test.auto.data$mu), 
                 sigma = sqrt(sum((test.auto.data$mu*test.auto.data$sigma)**2))/sum(test.auto.data$mu))
quantile(summed.auto, c(0.05, 0.5, 0.95))

data.76<-rbind(data.table(vol = summed, type = "ass_iid"), data.table(vol = summed.auto, type = "auto"))
ggplot(data.76, aes(vol, fill = type)) + 
geom_histogram(alpha = 0.5, position = 'identity')+
geom_vline(xintercept = sum(test.auto.data$obs_vol))

#-------

#simulate
sim.volume <-
    sapply(1:10000,
           function(x)
             with(test.iid.data,
                  sum(rGA(nrow(test.iid.data), 
                          mu = mu,
                          sigma = sigma))))
hist(sim.volume)
quantile(sim.volume, c(0.05, 0.5, 0.95))

data.77<-rbind(data.table(vol = summed, type = "math"), data.table(vol = sim.volume, type = "sim"))

ggplot(data.77, aes(vol, fill = type)) + 
geom_histogram(alpha = 0.5, position = 'identity') 

##Very close - essentially the same
```

### Compare obs vs predicted distributions
```{r, cdfs}
#ECDF
auto.2$surf<-"obs"
obs.1<-cbind(auto.2$obs_vol,auto.2$surf)
auto.2$surf<-"prd"
proj.1<-cbind(auto.2$V2,auto.2$surf)

data.78<-rbind(obs.1, proj.1)
data.78<-data.table(data.78)
data.78$V1<-as.numeric(data.78$V1)

plot_grid( ggplot(data.78, aes(V1, fill = V2)) + 
geom_histogram(alpha = 0.5, position = 'identity'),
ggplot(data.78, aes(V1, color = V2)) + 
stat_ecdf(alpha = 0.5, position = 'identity'), nrow =2 )

```

## Exercises

To demonstrate use of the calibration model we implemented a yield calibration module in [forestrycLUS](https://github.com/bcgov/clus/tree/master/R/SpaDES-modules/forestryCLUS). 

# References

Robinson, A.P., McLarin, M. and Moss, I., 2016. A simple way to incorporate uncertainty and risk into forest harvest scheduling. Forest Ecology and Management, 359, pp.11-18.
