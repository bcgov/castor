---
title: "BC Caribou Population Estimates"
author: "Tyler Muhly"
date: "22/08/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rpostgis)
library(data.table)
library(ggplot2)
library(plotly)
library(nlme)
library(ggspatial)
library(tidyr)
library(cowplot)
library(ggrepel)
source(paste0(here::here(), "/R/functions/R_Postgres.R"))
```

# Background
We need data on caribou population estimates. This creates a table of that information, including source of the information, to be uploaded into our database for use in moduels or as part of information summary.

Note: currently in contact with Nicola Dodd about getting this data

### Caribou population data
```{r, pop}
caribou_pop<-read.csv("T:/FOR/VIC/HTS/ANA/PROJECTS/CLUS/Data/caribou/population/herd_estimates_simple_20200106.csv")
caribou_pop<-data.table(caribou_pop)
caribou_pop<-caribou_pop[,year := as.integer(year)][,herd_name:= trimws(herd_name)]
conn<-DBI::dbConnect(dbDriver("PostgreSQL"), host=keyring::key_get('dbhost', keyring = 'postgreSQL'), dbname = keyring::key_get('dbname', keyring = 'postgreSQL'), port='5432' ,user=keyring::key_get('dbuser', keyring = 'postgreSQL') ,password= keyring::key_get('dbpass', keyring = 'postgreSQL'))

DBI::dbWriteTable(conn, c("public", "caribou_pop_simple"), value= caribou_pop, row.names = FALSE, overwrite = TRUE) 
dbDisconnect(conn)
```


### Wolf control data

Tyler pulled this dataset together -- to determine in which years population control activities take place.

```{r, pop_control}

wolf_actions<-read.csv("T:/FOR/VIC/HTS/ANA/PROJECTS/CLUS/Data/caribou/population/table_wolf_control_20200302.csv")
colnames(wolf_actions)<-c("herd_name", "year", "type")
wolf_actions<-data.table(wolf_actions)
wolf_actions<-wolf_actions[,herd_name:= trimws(herd_name)][herd_name == 'Wells Gray', herd_name:= 'Wells Gray North']

conn<-DBI::dbConnect(dbDriver("PostgreSQL"), host=keyring::key_get('dbhost', keyring = 'postgreSQL'), dbname = keyring::key_get('dbname', keyring = 'postgreSQL'), port='5432' ,user=keyring::key_get('dbuser', keyring = 'postgreSQL') ,password= keyring::key_get('dbpass', keyring = 'postgreSQL'))
#data.table(wolf_actions)[,herd_name:= gsub(" ", "_", herd_name)]
DBI::dbWriteTable(conn, c("public", "wolf_control"), value= wolf_actions, row.names = FALSE, overwrite = TRUE) 
dbDisconnect(conn)

```

### Merge wolf and pop data

```{r, final, echo=FALSE}
data_new<-data.table(merge(caribou_pop, wolf_actions, by.x = c("herd_name", "year"), by.y =c("herd_name", "year"), all.x = TRUE))
#Remove minimum counts and exper opinion estimates
data_new<-data_new[!(estimate_type %in% c("Expert Opinion", "Survey Observation","Minimum count", "Minimum Count", "Unknown"))]
#data_new<-data_new[!(estimate_type %in% c("Minimum count", "Minimum Count", "Unknown"))]

#remove dates confounded by population control responses
data_new<-data_new[is.na(type),]

#sort by herd_name and year
data_new[order(herd_name, year)]

#remove 'old' estimaste so this agrees with disturbance data
data_new<-data_new[year > 1975,]

#remove functionally extirpated populations
data_new<-data_new[pop_estimate > 0,]

#remove barkerville population after 2007 see QUESNEL HIGHLAND WOLF STERILIZATION PILOT ASSESSMENT 2012 An Independent Evaluation of the Response of Mountain Caribou
data_new<-data_new[!(herd_name == 'Barkerville' & year > 2001),]

data_new<-data_new[!(herd_name == 'Wells Gray North' & year > 2001),]

#Graham seems to have an outlier nad has a histroy of pop control
data_new<-data_new[!(herd_name == 'Graham'),]

#remove herds with only two data point
herds_counts <- data_new[, .(rowCount = .N), by = herd_name][rowCount >= 3,]
data_new<-data_new[herd_name %in% herds_counts$herd_name,]

#calc the averaged census lambda
data_new[, pop_lag:= lapply(.SD, function(x) c(NA,x[-.N])), by = herd_name, .SDcols = "pop_estimate"]

data_new[, year_lag:= lapply(.SD, function(x) c(NA,x[-.N])), by = herd_name, .SDcols = "year"]
data_new[, lambda:= (pop_estimate/pop_lag)**(1/(year-year_lag))]
data_new[, pop.change:= (pop_estimate/pop_lag)-1]
#data_new[,c("pop_lag", "year_lag"):= list(NULL, NULL)]  

#calc the averaged census lambda
data_new[, year.0 := min(year), by=herd_name]
data_new[, pop.max := max(pop_estimate), by=herd_name]
data_new[, per.pop := pop_estimate/pop.max]

pop0<-data_new[year==year.0, c("herd_name","pop_estimate")]
setnames(pop0, "pop_estimate", "pop.0")
data_new<-merge(data_new, pop0, by.x = "herd_name", by.y = "herd_name")
data_new[, lambda.ratio:= (pop_estimate/pop.0)]
data_new[year==year.0, lambda.ratio:= NA]

data_new[, lambda.finite:= (pop_estimate/pop.0)**(1/(year-year.0))]
data_new[year==year.0, lambda.finite:= NA]

# From https://www.nature.com/scitable/knowledge/library/how-populations-grow-the-exponential-and-logistic-13240157/
data_new[, log.pop:= log(pop_estimate)]
data_new[, lambda.dif:= log(pop_estimate)-log(pop.0)]
data_new[, lambda.dift:= lambda.dif/(year-year.0)]
data_new[, lambda.dif.n0:= log(pop_estimate)-log(pop_lag)]
data_new[, lambda.dift.n0:= lambda.dif.n0/(year-year_lag)]



#rename the herds so that they link with CLUS
data_new[, herd_name:= lapply(.SD, function(x) { gsub("-", "_", x)}), .SDcols = "herd_name"]
data_new[, herd_name:= lapply(.SD, function(x) { gsub(" ", "_", x)}), .SDcols = "herd_name"]


conn<-DBI::dbConnect(dbDriver("PostgreSQL"), host=keyring::key_get('dbhost', keyring = 'postgreSQL'), dbname = keyring::key_get('dbname', keyring = 'postgreSQL'), port='5432' ,user=keyring::key_get('dbuser', keyring = 'postgreSQL') ,password= keyring::key_get('dbpass', keyring = 'postgreSQL'))

DBI::dbWriteTable(conn, c("public", "caribou_trend"), value= data_new, row.names = FALSE, overwrite = TRUE) 
dbDisconnect(conn)

table2<-data_new[year==year.0, c("herd_name", "pop.0")]

```

#### Map of herds
```{r, graph_pop}
herd.spat<-getSpatialQuery( "Select * from public.bc_caribou_linework_v20200507_shp_core_matrix")

#Make a grouping variable
herd.spat$herd_hab<-herd.spat$herd_name
non.herds<-c('Barkerville', 'Wells_Gray_South','Wells_Gray_North','Central_Selkirks','Columbia_North','Columbia_South', 'Groundhog', 'Hart_Ranges', 'Narraway', 'Narrow_Lake', 'North_Cariboo', 'Purcell_Central', 'Purcells_South', 'South_Selkirks')
herd.spat[herd.spat$herd_name %in% non.herds,]$herd_hab<-paste(herd.spat[herd.spat$herd_name %in% non.herds,]$herd_name,herd.spat[herd.spat$herd_name %in% non.herds,]$bc_habitat)

#Dissolve
herd.spat1<-herd.spat %>%
   group_by(herd_hab) %>%
   summarise()

#Add matrix/core and herd_name columns
herd.spat1$crit <- 0
herd.spat1[herd.spat1$herd_hab %like% "Matrix", ]$crit <- 1
herd.spat1[herd.spat1$herd_hab %like% "Core", ]$crit <- 2
string.list<-unlist(strsplit(herd.spat1$herd_hab, ' '))
herd.spat1$herd_name<-string.list[!string.list %in% c('Matrix' , 'Core')]

#Get the map of canada
if (!file.exists("./src/ref/ne_50m_admin_1_states_provinces_lakes/ne_50m_admin_1_states_provinces_lakes.dbf")){
  download.file(file.path('http://www.naturalearthdata.com/http/',
                          'www.naturalearthdata.com/download/50m/cultural',
                          'ne_50m_admin_1_states_provinces_lakes.zip'), 
                f <- tempfile())
  unzip(f, exdir = "./src/ref/ne_50m_admin_1_states_provinces_lakes")
  rm(f)
}

region <- readOGR("./src/ref/ne_50m_admin_1_states_provinces_lakes", 'ne_50m_admin_1_states_provinces_lakes', encoding='UTF-8')

canada = subset(region, name %in% c("British Columbia", "Alberta", "Saskatchewan", "Manitoba", "Ontario", "QuÃ©bec", "New Brunswick", "Prince Edward Island", "Nova Scotia", "Newfoundland and Labrador", "Yukon", "Northwest Territories", "Nunavut")) #notice Quebec has a problem

canada<-st_as_sf(canada)
canada$groups<-1
canada[canada$name == 'British Columbia',]$groups<-0
canada1<-canada %>%
   group_by(groups) %>%
   summarise()
canada1$prov<-''
canada1[canada1$groups == 0,]$prov<-"BC" 

#Get the herd boundries
herd.spat<-getSpatialQuery( "Select * from public.bc_caribou_herd_boundary_v20200507 where herd_name in ('Barkerville', 'Wells_Gray_South','Wells_Gray_North','Central_Selkirks','Columbia_North','Columbia_South', 'Groundhog', 'Hart_Ranges', 'Narraway', 'Narrow_Lake', 'North_Cariboo', 'Purcell_Central', 'Purcells_South', 'South_Selkirks' )")
#herd.spat2<-herd.spat %>% group_by(herd_name) %>% summarise()

#Get the bounding box of the study area
southern.mountain.bb = st_as_sfc(st_bbox(getSpatialQuery( "Select * from public.bc_caribou_herd_boundary_v20200507 where herd_name in ('Barkerville', 'Wells_Gray_South','Wells_Gray_North','Central_Selkirks','Columbia_North','Columbia_South', 'Groundhog', 'Hart_Ranges', 'Narraway', 'Narrow_Lake', 'North_Cariboo', 'Purcell_Central', 'Purcells_South', 'South_Selkirks', 'Rainbows' )")))


xys<-st_coordinates(st_centroid(st_transform(herd.spat, 4326)))
herd.spat2<-cbind(herd.spat, xys)

herds.inc<-unique(gsub("_", " ", data_new$herd_name))
herd.spat2$herd_name2<-gsub("_", " ", herd.spat2$herd_name)

#herd.spat2[!herd.spat2$herd_name2 %in% herds.inc, ]$herd_name2<-NA
#herd.spat2$herd_name2

inset<-ggplot() + 
  geom_sf(data = canada1,  fill = "white") + 
  geom_sf(data = southern.mountain.bb, fill = NA, color = "red", size = 1) +
  geom_label( aes(x=-100,y=70, label = "Canada"), size = 3)+
  geom_text( aes(x=-112,y=58.5, label = "BC"), size = 2) +
  theme_void()

main<-ggplot() +
    geom_sf(data = canada1, aes(alpha = 0.4), show.legend=FALSE)+
    geom_sf(data = herd.spat1[herd.spat1$crit==1,], aes(fill = "yellow"), color = NA, show.legend=FALSE )+
  geom_sf(data = herd.spat1[herd.spat1$crit==2,], aes(fill = "blue"), color = NA, show.legend=FALSE )+
    
    geom_sf(data = herd.spat2, aes(alpha = 0.2), show.legend=FALSE ) +
    #geom_text_repel(data = herd.spat2, aes(x=X, y=Y, label = herd_name), fontface = "bold", size = 1.5)+
  geom_text_repel(data = herd.spat2, aes(x=X, y=Y, label = herd_name2), 
        fontface = "bold", size = 3,nudge_x = c(-4,-2.25,-4,-5,-4,-4,-4,-3,-4,-4,-3.15,-2.25,-3,4), nudge_y = c(-0.15,0,0.25,1.5,-0.25,-0.25,0.25,0,1,0.15,0.25,0.05,0,0.75))+
    coord_sf(xlim = c(-128,-115.2), ylim = c(48.9, 55.4), expand = FALSE) +
    theme_bw()+
    xlab("Longitude") + ylab("Latitude") +
    annotation_scale(location = "bl", width_hint = 0.4) +
    annotation_north_arrow(location = "bl", which_north = "true", 
        style = north_arrow_fancy_orienteering, pad_y = unit(0.3, "in")) 

ggdraw() +
  draw_plot(main) +
  draw_plot(inset, x = 0.63, y = 0.688, width = 0.29, height = 0.28)


```
#### Graph of population data
```{r, graph_pop}
conn<-DBI::dbConnect(dbDriver("PostgreSQL"), host=keyring::key_get('dbhost', keyring = 'postgreSQL'), dbname = keyring::key_get('dbname', keyring = 'postgreSQL'), port='5432' ,user=keyring::key_get('dbuser', keyring = 'postgreSQL') ,password= keyring::key_get('dbpass', keyring = 'postgreSQL'))
data_new<-dbGetQuery(conn, "Select * from caribou_trend where herd_name not in ('Muskwa', 'Pink_Mountain', 'Chase', 'Wolverine');")
dbDisconnect(conn)

ggplotly(ggplot(data = data_new, aes(x=year, y = lambda.dift, color = herd_name))+
  geom_point() + geom_line())
```

#### Get the disturbance information

```{r, disturbance}
conn<-DBI::dbConnect(dbDriver("PostgreSQL"), host=keyring::key_get('vmdbhost', keyring = 'postgreSQL'), dbname = keyring::key_get('vmdbname', keyring = 'postgreSQL'), port='5432' ,user=keyring::key_get('vmdbuser', keyring = 'postgreSQL') ,password= keyring::key_get('vmdbpass', keyring = 'postgreSQL'))

disturb<-data.table(dbGetQuery(conn, paste0("SELECT * from disturbance_measures.disturbance where scenario in ('", paste(unique(data_new$herd_name), collapse = "', '"),"');")))

seral<-data.table(dbGetQuery(conn, paste0("SELECT * from disturbance_measures.survival where scenario in ('", paste(unique(data_new$herd_name), collapse = "', '"),"');")))

rsf<-data.table(dbGetQuery(conn, paste0("SELECT * from disturbance_measures.rsf where scenario in ('", paste(unique(data_new$herd_name), collapse = "', '"),"');")))

dbDisconnect(conn)

conn<-DBI::dbConnect(dbDriver("PostgreSQL"), host=keyring::key_get('dbhost', keyring = 'postgreSQL'), dbname = keyring::key_get('dbname', keyring = 'postgreSQL'), port='5432' ,user=keyring::key_get('dbuser', keyring = 'postgreSQL') ,password= keyring::key_get('dbpass', keyring = 'postgreSQL'))
fire<-data.table(dbGetQuery(conn, paste0("SELECT sumarea/10000 as area_burn, fire_year as year, herd_name, bc_habitat as critical_hab from public.fire_sum_crithab where herd_name in ('", paste(unique(data_new$herd_name), collapse = "', '"),"') order by herd_name, year;")))
dbDisconnect(conn)

#fill in the years with zero
fire2<-fire %>%
  group_by(herd_name, critical_hab) %>% 
  complete(year = full_seq(year,1), fill = list(area_burn = 0))

fire3<-data.table(fire2)
fire3[, burn40 := zoo::rollapplyr(area_burn, 40, FUN = sum, fill=0), by = c("herd_name", "critical_hab")] 


disturb<-disturb[,year:=as.integer(timeperiod+1980)]
setnames(disturb, "scenario", "herd_name")

seral<-seral[,year:=as.integer(timeperiod+1980)]
setnames(seral, c("scenario", "herd_bounds"), c("herd_name","critical_hab"))

rsf<-rsf[,year:=as.integer(timeperiod+1980)]
setnames(rsf, "scenario", "herd_name")

#merge them together
data.0<-merge(disturb, rsf, by.x = c("herd_name", "year", "critical_hab"), by.y = c("herd_name", "year", "critical_hab"))
data.1<-merge(data.0, seral, by.x = c("herd_name", "year", "critical_hab"), by.y = c("herd_name", "year", "critical_hab"))

data.1[, early_seral:=prop_age*area]
#rename critical_hab to either matrix or core
data.1[critical_hab %like% "Matrix",critical_hab:= 'Matrix' ]
data.1[critical_hab %like% "Core",critical_hab:= 'Core' ]

#Merge in the fire disturbance
data.2<-merge(data.1, fire3, by.x =c("herd_name", "year", "critical_hab"), by.y = c("herd_name", "year", "critical_hab") )

```
### Create the linkage
```{r, linkage}

data.3<-merge(data.2, data_new, by.x = c("herd_name", "year"), by.y = c("herd_name", "year"))
data.3[, pop.den:= pop_estimate/area]

#subset by habitat type
data.core<-data.3[critical_hab== 'Core', c("herd_name", "year", "pop_estimate", "lambda", "year.0","pop.0","pop.den", "area", "lambda.ratio", "lambda.finite", "per.pop", "early_seral", "dist", "dist500", "sum_rsf_hat", "sum_rsf_hat_75","per_rsf_hat_75", "pop_lag", "log.pop", "year_lag", "burn40", "survival_rate","lambda.dift","lambda.dif", "pop.change","lambda.dift.n0","lambda.dif.n0")]
setnames(data.core, c("early_seral", "dist", "dist500", "sum_rsf_hat", "sum_rsf_hat_75", "area", "pop_lag", "year_lag","burn40","per_rsf_hat_75","survival_rate","log.pop","lambda.dift","lambda.dif","pop.change","lambda.dift.n0","lambda.dif.n0"), c("core.early.seral", "core.dist", "core.dist500", "core.sum.rsf.hat", "core.sum.rsf.hat.75", "core.area", "pop_lag", "year_lag","core.burn40","core.per.rsf.hat.75","core.survival.rate","log.pop","lambda.dift","lambda.dif","pop.change","lambda.dift.n0","lambda.dif.n0"))

data.matrix<-data.3[critical_hab == 'Matrix',c("herd_name", "year", "early_seral", "dist", "dist500", "sum_rsf_hat", "sum_rsf_hat_75", "area", "burn40", "per_rsf_hat_75", "survival_rate")]
setnames(data.matrix, c("early_seral", "dist", "dist500", "sum_rsf_hat", "sum_rsf_hat_75", "area", "burn40","per_rsf_hat_75", "survival_rate"), c("matrix.early.seral", "matrix.dist", "matrix.dist500", "matrix.sum.rsf.hat", "matrix.sum.rsf.hat.75", "matrix.area", "matrix.burn40","matrix.per.rsf.hat.75","matrix.survival.rate"))
data.core<-data.core[,core.burn40.per:=core.burn40/core.area]
data.matrix<-data.matrix[,matrix.burn40.per:=matrix.burn40/matrix.area]

data.set<-merge(data.core, data.matrix, by.x = c("herd_name", "year"), by.y = c("herd_name", "year"))
data.set[, time:=year-year.0]

#Calc diturbance indicators
data.set[, core.dist.per:= core.dist/core.area]
data.set[, core.dist500.per:= core.dist500/core.area]
data.set[, core.early.seral.per:= core.early.seral/core.area]
data.set[, core.rsf.avg:= core.sum.rsf.hat/core.area]
data.set[, matrix.dist.per:= matrix.dist/matrix.area]
data.set[, matrix.dist500.per:= matrix.dist500/matrix.area]
data.set[, matrix.early.seral.per:= core.early.seral/matrix.area]
data.set[, matrix.rsf.avg:= matrix.sum.rsf.hat/matrix.area]

#RATES
##Core
#data.set[, core.burn40.rate:= lapply(.SD, function(x) c(NA,x[-.N])), by = herd_name, .SDcols = "core.burn40"]
data.set.0<-data.set[year == year.0, c("herd_name", "core.burn40","matrix.burn40", "core.early.seral","matrix.early.seral", "core.dist", "matrix.dist", "core.dist500", "matrix.dist500", "core.sum.rsf.hat", "matrix.sum.rsf.hat")]
setnames(data.set.0,c("herd_name", "core.burn40","matrix.burn40", "core.early.seral","matrix.early.seral","core.dist", "matrix.dist", "core.dist500", "matrix.dist500", "core.sum.rsf.hat", "matrix.sum.rsf.hat"),c("herd_name", "core.burn40.0","matrix.burn40.0","core.early.seral.0","matrix.early.seral.0", "core.dist.0", "matrix.dist.0", "core.dist500.0", "matrix.dist500.0", "core.sum.rsf.hat.0", "matrix.sum.rsf.hat.0"))
data.set<-merge(data.set, data.set.0, by.x = "herd_name", by.y = "herd_name", all.x = TRUE)
data.set[, core.burn40.rate:= (core.burn40-core.burn40.0)/core.burn40.0]
data.set[, core.early.seral.rate:= (core.early.seral-core.early.seral.0)/core.early.seral.0]
data.set[, core.dist.rate:= (core.dist-core.dist.0)/core.dist.0]
data.set[, core.dist500.rate:= (core.dist500-core.dist500.0)/core.dist500.0]
data.set[, core.rsf.rate:= (core.sum.rsf.hat-core.sum.rsf.hat.0)/core.sum.rsf.hat.0]

data.set[, core.burn40.rate2:= (core.burn40-core.burn40.0)/(year-year.0)]
data.set[, core.early.seral.rate2:= (core.early.seral-core.early.seral.0)/(year-year.0)]
data.set[, core.dist.rate2:= (core.dist-core.dist.0)/(year-year.0)]
data.set[, core.dist500.rate2:= (core.dist500-core.dist500.0)/(year-year.0)]
data.set[, core.rsf.rate2:= (core.sum.rsf.hat-core.sum.rsf.hat.0)/(year-year.0)]

##Matrix
data.set[, matrix.burn40.rate:= (matrix.burn40-matrix.burn40.0)/matrix.burn40.0]
data.set[, matrix.early.seral.rate:= (matrix.early.seral-matrix.early.seral.0)/matrix.early.seral.0]
data.set[, matrix.dist.rate:= (matrix.dist-matrix.dist.0)/matrix.dist.0]
data.set[, matrix.dist500.rate:= (matrix.dist500-matrix.dist500.0)/matrix.dist500.0]
data.set[, matrix.rsf.rate:= (matrix.sum.rsf.hat-matrix.sum.rsf.hat.0)/matrix.sum.rsf.hat.0]

data.set[, matrix.burn40.rate2:= (matrix.burn40-matrix.burn40.0)/(year-year.0)]
data.set[, matrix.early.seral.rate2:= (matrix.early.seral-matrix.early.seral.0)/(year-year.0)]
data.set[, matrix.dist.rate2:= (matrix.dist-matrix.dist.0)/(year-year.0)]
data.set[, matrix.dist500.rate2:= (matrix.dist500-matrix.dist500.0)/(year-year.0)]
data.set[, matrix.rsf.rate2:= (matrix.sum.rsf.hat-matrix.sum.rsf.hat.0)/(year-year.0)]

table1<- data.set.0[,c("herd_name", "core.early.seral.0","core.dist.0","core.dist500.0", "matrix.early.seral.0","matrix.dist.0","matrix.dist500.0")]
```

# Figure of disturbance profile
```{r, dist_graph}
one0<-data.set[, c("herd_name", "year","core.early.seral.per")]
setnames(one0, "core.early.seral.per" , "value")
one0[, dm:='C']
one0[, type:='PHab']
one1<-data.set[, c("herd_name", "year","core.dist.per")]
setnames(one1, "core.dist.per" , "value")
one1[, dm:='CR']
one1[, type:='PHab']
one2<-data.set[, c("herd_name", "year","core.dist500.per")]
setnames(one2, "core.dist500.per" , "value")
one2[, dm:='CR500']
one2[, type:='PHab']
one3<-data.set[, c("herd_name", "year","core.early.seral.rate")]
setnames(one3, "core.early.seral.rate" , "value")
one3[, dm:='C']
one3[, type:='PInit']
one4<-data.set[, c("herd_name", "year","core.dist.rate")]
setnames(one4, "core.dist.rate" , "value")
one4[, dm:='CR']
one4[, type:='PInit']
one5<-data.set[, c("herd_name", "year","core.dist500.rate")]
setnames(one5, "core.dist500.rate" , "value")
one5[, dm:='CR500']
one5[, type:='PInit']

t0<-data.set[, c("herd_name", "year","matrix.early.seral.per")]
setnames(t0, "matrix.early.seral.per" , "value")
t0[, dm:='C']
t0[, type:='PHab']
t1<-data.set[, c("herd_name", "year","matrix.dist.per")]
setnames(t1, "matrix.dist.per" , "value")
t1[, dm:='CR']
t1[, type:='PHab']
t2<-data.set[, c("herd_name", "year","matrix.dist500.per")]
setnames(t2, "matrix.dist500.per" , "value")
t2[, dm:='CR500']
t2[, type:='PHab']
t3<-data.set[, c("herd_name", "year","matrix.early.seral.rate")]
setnames(t3, "matrix.early.seral.rate" , "value")
t3[, dm:='C']
t3[, type:='PInit']
t4<-data.set[, c("herd_name", "year","matrix.dist.rate")]
setnames(t4, "matrix.dist.rate" , "value")
t4[, dm:='CR']
t4[, type:='PInit']
t5<-data.set[, c("herd_name", "year","matrix.dist500.rate")]
setnames(t5, "matrix.dist500.rate" , "value")
t5[, dm:='CR500']
t5[, type:='PInit']

core.graph.dist<-rbind(one0,one1,one2,one3,one4,one5)
core.graph.dist[, hab:='Core']
matrix.graph.dist<-rbind(t0,t1,t2,t3,t4,t5)
matrix.graph.dist[,hab:='Matrix']


graph.dist<-rbind(core.graph.dist,matrix.graph.dist)
graph.dist<-graph.dist[, herd_name:=lapply(.SD, function(x) { gsub("_", " ", x)}), .SDcols = "herd_name"]
out.graph.dist<- ggplot(data = graph.dist, aes(x = year, y =value, color = herd_name )) +
  facet_grid(type+hab~dm  , scales='free') +
  labs(y = "Disturbance Measure (%)", x = "Year")+
  geom_point() +
  geom_line() +
  guides(color=guide_legend(title = "Herd")) +
  theme_bw() 

out.graph.dist
```

## Plot between core disturbance and ratio between population estimates
```{r, pop_graph_core}
p1<-ggplot(data = data.set, aes(x =core.early.seral.rate, y =lambda.dift, color = herd_name )) +  geom_point() 

p2<-ggplot(data = data.set, aes(x =core.dist.rate, y =lambda.dift, color = herd_name  )) + geom_point() 

p3<-ggplot(data = data.set, aes(x =core.dist500.rate, y = lambda.dift, color = herd_name  )) + geom_point() 

p4<-ggplot(data = data.set, aes(x =core.burn40.rate, y = lambda.dift , color = herd_name)) + geom_point() 

gridExtra::grid.arrange(p1,p2,p3,p4)

ggplotly(p2)
```

## Plot between matrix disturbance and ratio between population estimates
```{r, pop_graph_core}
p1<-ggplot(data = data.set, aes(x =matrix.early.seral.rate, y =lambda.dift, color = herd_name )) +  geom_point() 

p2<-ggplot(data = data.set, aes(x =matrix.dist.rate, y =lambda.dift, color = herd_name  )) + geom_point() 

p3<-ggplot(data = data.set, aes(x =matrix.dist500.rate, y = lambda.dift, color = herd_name  )) + geom_point() 

p4<-ggplot(data = data.set, aes(x =matrix.rsf.rate, y = lambda.dift , color = herd_name)) + geom_point() 

p5<-ggplot(data = data.set, aes(x =matrix.burn40.rate, y = lambda.dift , color = herd_name)) + geom_point() 

gridExtra::grid.arrange(p1,p2,p3,p4,p5)

ggplotly(p3)
```
.(count = .N, var = sum(VAR))
# Table of disturbance and population
```{r, table1}
table1<-data.set[,.(Core = mean(core.area), Matrix = mean(matrix.area),YearMin= min(year), YearMax= max(year),n = .N, popavg = round(mean(pop_estimate),0), popmax = max(pop_estimate), popmin = min(pop_estimate) ), by = "herd_name"]
table1
```
#DISTRUBITIONAL ASSUMPTIONS

I start with a normal distribution- since the change in population is likely symetrical distribution. This assumption seems valid.
```{r, assump}
library(gamlss)
histDist(lambda.dift,family="NO", data=data.set[!is.na(lambda),], nbins = 10)
histDist(lambda,family="LNO", data=data.set[!is.na(lambda),], nbins = 10)

```
#CORRELATION BETWEEN X
```{r, cor_x}
library(ggcorrplot)
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jdk-14.0.1')
dat<-data.set[!is.na(lambda.dift),c("core.early.seral.per", "core.early.seral.rate","core.dist.per", "core.dist.rate","core.dist500.per", "core.dist500.rate","matrix.early.seral.per", "matrix.early.seral.rate","matrix.dist.per", "matrix.dist.rate", "matrix.dist500.per", "matrix.dist500.rate")]
library(usdm)
dat<-data.set[!is.na(lambda.dift),c("core.early.seral.per", "core.early.seral.rate","core.dist.per", "core.dist.rate","core.dist500.per", "core.dist500.rate","matrix.early.seral.per", "matrix.early.seral.rate","matrix.dist.per", "matrix.dist.rate", "matrix.dist500.per", "matrix.dist500.rate")]

test<-data.set[!is.na(lambda.dift),c("core.early.seral.per","matrix.early.seral.per")]
test<-data.set[!is.na(lambda.dift),c("core.early.seral.rate","matrix.early.seral.rate")]
test<-data.set[!is.na(lambda.dift),c("core.dist.per","matrix.dist.per")]
test<-data.set[!is.na(lambda.dift),c("core.dist.rate","matrix.dist.rate")]

test<-data.set[!is.na(lambda.dift),c("core.dist500.per","matrix.dist500.per")]
test<-data.set[!is.na(lambda.dift),c("core.dist500.rate","matrix.dist500.rate")]


vif(test)
```


#MODEL SETTINGS

Here the data set is cleaned up to only include those variables that are important to the modelling process. Further, the control parameters are set for the model fitting algorithums
```{r, setting}
model.data<-na.omit(data.set[,c("herd_name","pop_estimate", "pop.0", "time", "year", "lambda.ratio","lambda", "lambda.finite", "lambda.dift", "lambda.dif", "core.early.seral.per", "core.dist.per", "core.dist500.per", "core.burn40.per","core.per.rsf.hat.75","core.sum.rsf.hat","core.rsf.avg", "core.early.seral.rate", "core.dist.rate", "core.dist500.rate", "core.rsf.rate","core.burn40.rate", "matrix.early.seral.per", "matrix.dist.per", "matrix.dist500.per", "matrix.burn40.per","matrix.per.rsf.hat.75","matrix.sum.rsf.hat","matrix.rsf.avg","matrix.early.seral.rate", "matrix.dist.rate", "matrix.dist500.rate", "matrix.rsf.rate","matrix.burn40.rate")])
con1 <- gamlss.control(c.crit=0.001, n.cyc=5000,msMaxIter=1000000)
xys2<-herd.spat2[,c("herd_name", "X", "Y")]
xys2$shape<-NULL
xys2<-data.table(xys2)
#Add in the X and Y from the xys object
model.data<-merge(model.data, xys2, by.x= "herd_name", by.y = "herd_name")
# Add the null group
model.data[,group:=1]
model.data[,l.lambda:=log(lambda)]
```

# SUMMARY OF DISTURBANCE
```{r,sum_dist}

summary(model.data)
```
#NULL Model

Note that herd_name is the identifier for each herd. This model is simply the average of the log ratio of population change by herd = exp(-0.48) = 0.619 or a decline of ~40% across the years surveyed
```{r, reduced_model}
m0.a <- lme(lambda.dift ~ 1 , random=~ 1|group, data = model.data, method = 'REML', control = con1)
summary(m0.a) #AIC:273, logl:-133
plot(m0.a)

#Try adding a random effect for herd. 
m0.b.reml <- lme(lambda.dift ~ 1 , random=~ 1|herd_name, data = model.data, method = 'REML', control = con1)
m0.b <- lme(lambda.dift ~ 1 , random=~ 1|herd_name, data = model.data, method = 'ML', control = con1)
acf(residuals(m0.b,type="normalized"))
summary(m0.b)#AIC:183, logl:-88.7
plot(m0.b)# variances are different by herd

#anova(m0.a,m0.b)
#Try adding a random effect for herd. Also, a different Variance for each herd. "The lme function allow the modeling of heteroscesdasticity of the within-error group via a weights argument. This topic will be covered in detail in § 5.2, but, for now, it suffices to know that the varIdent variance function structure allows different variances for each level of a factor and can be used to fit the heteroscedastic model [...]" Pinheiro and Bates, p. 177
VarCorr(m0.b)
getVarCov(m0.b)

m0.c <- lme(lambda.dift ~ 1 , random=~ 1|herd_name, weights = varIdent(form = ~1|herd_name), data = model.data, method = 'REML', control = con1)
summary(m0.c)#AIC: 136, logl:-52
plot(m0.c)# residuals have trend -- over parameterizing
#anova(m0.b, m0.c) # model.c is better than model.b LRT: p<0.001
acf(residuals(m0.c,type="normalized"))# Note: |r| > 0.2 -- issues with autocorrelation...but lags hard to fit with the limited data.
#TRY a AR1 correlation structure? Doesn't fit well --have to change residuals to normalized!!!! Too many parameters to fit....

m0.d <- lme(lambda.dift ~ 1 , random=~ 1|herd_name, correlation = corAR1(value = 0.3, form = ∼time|herd_name), data = model.data, method = 'REML', control = con1)
#anova(m0.c, m0.d) # model m0.d is better LRT: p<0.001
acf(residuals(m0.d,type="normalized"), lag.max = 10) # phi = 0.9. No significant lags
plot( fitted(m0.d, level =1),residuals(m0.d, type="normalized"))# variances are homogenous
abline(0,0, col = 'red')
summary(m0.d)
VarCorr(m0.d)
intervals(m0.d)
#anova(m0.b,m0.d)

m0.e <- lme(lambda.dift ~ 1 , random=~ 1|herd_name, correlation = corAR1(form=~time ), data = model.data, method = 'REML', control = con1)
acf(residuals(m0.e,type="normalized")) # phi = 0.9. No significant lags
plot( fitted(m0.e, level =1),residuals(m0.e, type="normalized"))# variances are homogenous
#anova(m0.e, m0.c) 
#anova(m0.e, m0.d) 
```

## NULL: Using lambda (annual change)
```{r}
l0.a <- lme(l.lambda ~ 1 , random=~ 1|group, data = model.data, method = 'REML', control = con1)
summary(l0.a) #AIC:61, logl:-27
plot(l0.a)

#Try adding a random effect for herd. 
l0.b <- lme(l.lambda ~ 1 , random=~ 1|herd_name, data = model.data, method = 'REML', control = con1)
summary(l0.b)#AIC:61, logl:-27
plot(l0.b)# va

l0.d <- lme(l.lambda ~ 1 , random=~ 1|herd_name, correlation = corAR1(value = 0.8, form = ∼time|herd_name), data = model.data, method = 'REML', control = con1)
#anova(m0.c, m0.d) # model m0.d is better LRT: p<0.001
acf(residuals(l0.d,type="normalized")) # phi = 0.9. No significant lags
plot( fitted(l0.d, level =1),residuals(l0.d, type="normalized"))# variances are homogenous
abline(0,0, col = 'red')
summary(l0.d)#AIC:57, logl:-24.7

```
#Alternative models

Comaring the use of burn40, early.seral, dist, dist500 and rsf. Null random intercept model has AIC=206, Rsq=0.586, cor = 0.76888.

## Percentage burned less 40 years (burn40)

Not significantly impating the pop change after accounting for herd level impacts

```{r, burn40}
#burn40 -- includes only fires, no human disturbances (cutblocks)
#Use ML estimation since fixed effects will change amoung models
#---PERCENTAGE---

l.burn.per <- lme(l.lambda ~ 1 + core.burn40.per*matrix.burn40.per, random=~ 1|herd_name, correlation = corAR1(0.8, form = ~time|herd_name), data = model.data, method = 'ML', control = con1)
##Diagnostics
acf(residuals(l.burn.per, type = 'normalized'),lag.max =10) # No problem with AC
plot( fitted(l.burn.per),residuals(l.burn.per, type="normalized"))# variances are homogenous
abline(0,0, col = 'red')
cor(fitted(l.burn.per),model.data$lambda) #0.796
plot(model.data$lambda~fitted(l.burn.per ))
abline(0,1, col = "red")
abline(0,0, col = "yellow")
summary(l.burn.per)

#correlation = corAR1(0.8, form = ~time|herd_name)
burn.per <- lme(lambda.dift ~ 1 + core.burn40.per*matrix.burn40.per, random=~ 1|herd_name, data = model.data, method = 'ML', control = con1)
##Diagnostics
acf(residuals(burn.per, type = 'normalized'),lag.max =10) # No problem with AC
plot( fitted(burn.per),residuals(burn.per, type="normalized"))# variances are homogenous
abline(0,0, col = 'red')
cor(fitted(burn.per),model.data$lambda.dift) #0.796
plot(model.data$lambda.dift~fitted(burn.per ))
abline(0,1, col = "red")
abline(0,0, col = "yellow")
summary(burn.per)

#---RATE----
l.burn.rate <- lme(lambda ~ 1 + core.burn40.rate*matrix.burn40.rate, random=~ 1|herd_name,  correlation = corAR1(0.8, form = ~time|herd_name), data = model.data, method = 'ML', control = con1)
##Diagnostics
acf(residuals(l.burn.rate, type = 'normalized'),lag.max =10) # No problem with AC
plot( fitted(l.burn.rate),residuals(l.burn.rate, type="normalized"))# variances are homogenous
abline(0,0, col = 'red')
cor(fitted(l.burn.rate, level= 1),model.data$lambda) #0.8547
plot(model.data$lambda~fitted(l.burn.rate ))
abline(0,1, col = "red")
abline(0,0, col = "yellow")
summary(l.burn.rate)

# correlation = corAR1(0.8, form = ~time|herd_name)
burn.rate <- lme(lambda.dift ~ 1 + core.burn40.rate*matrix.burn40.rate, random=~ 1|herd_name, data = model.data, method = 'ML', control = con1)
##Diagnostics
acf(residuals(burn.rate, type = 'normalized'),lag.max =10) # No problem with AC
plot( fitted(burn.rate),residuals(burn.rate, type="normalized"))# variances are homogenous
abline(0,0, col = 'red')
cor(fitted(burn.rate, level= 1),model.data$lambda.dift) #0.8547
plot(model.data$lambda.dift~fitted(burn.rate ))
abline(0,1, col = "red")
abline(0,0, col = "yellow")
summary(burn.rate)

anova(burn.per,burn.rate)
#Conclusion burn40 not a signifcant disturbance measure on its own
```

#Early Seral Stage which is just clear cuts -- doesn't include burns
```{r, eary_seral}
#---Percentage---
l.early.seral.per<- lme(l.lambda ~ core.early.seral.per*matrix.early.seral.per, random=~ 1|herd_name, method = 'ML', correlation = corAR1(0.3, form =~time|herd_name), data = model.data, control = con1)
##Diagnostics
acf(residuals(l.early.seral.per , type = 'normalized'),lag.max =10)#No issues
plot( fitted(l.early.seral.per),residuals(l.early.seral.per, type="normalized"))# variances are homogenous
abline(0,0, col = 'red')
cor(fitted(l.early.seral.per, level=1),model.data$l.lambda) #0.797
plot(model.data$l.lambda~fitted(l.early.seral.per))
abline(0,1, col = "red")
abline(0,0, col = "yellow")
summary(l.early.seral.per)

early.seral.per.reml<- lme(lambda.dift ~ core.early.seral.per*matrix.early.seral.per, random=~ 1|herd_name, method = 'REML', data = model.data, control = con1)

#early.seral.per.reml.slope<- lme(lambda.dift ~ matrix.early.seral.per , random=~matrix.early.seral.per|herd_name, method = 'REML', data = model.data, control = con1)

#anova(early.seral.per.reml,early.seral.per.reml.slope)

early.seral.per<- lme(lambda.dift ~ core.early.seral.per*matrix.early.seral.per, random=~ 1|herd_name, method = 'ML', data = model.data, control = con1)
##Diagnostics
acf(residuals(early.seral.per , type = 'normalized'),lag.max =10)#No issues
plot( fitted(early.seral.per),residuals(early.seral.per, type="normalized"))# variances are homogenous
abline(0,0, col = 'red')
cor(fitted(early.seral.per.reml, level=0),model.data$lambda.dift) #0.797
plot(model.data$lambda.dift~fitted(early.seral.per))
abline(0,1, col = "red")
abline(0,0, col = "yellow")
summary(early.seral.per)


#---Rate---
l.early.seral.rate<- lme(l.lambda ~  core.early.seral.rate*matrix.early.seral.rate, random=~ 1|herd_name, method = 'ML', correlation = corAR1(0.3, form =~time|herd_name), data = model.data, control = con1)
##Diagnostics
acf(residuals(l.early.seral.rate , type = 'normalized'),lag.max =10)#No issues
plot( fitted(l.early.seral.rate),residuals(l.early.seral.rate, type="normalized"))# variances are homogenous
abline(0,0, col = 'red')
cor(fitted(l.early.seral.rate, level =1),model.data$l.lambda) #0.8767
plot(model.data$l.lambda~fitted(l.early.seral.rate))
abline(0,1, col = "red")
abline(0,0, col = "yellow")
summary(l.early.seral.rate)

early.seral.rate.reml<- lme(lambda.dift ~  core.early.seral.rate*matrix.early.seral.rate, random=~ 1|herd_name, method = 'REML', data = model.data, control = con1)

early.seral.rate.reml.slope<- lme(lambda.dift ~  core.early.seral.rate*matrix.early.seral.rate, random=~ 1+core.early.seral.rate|herd_name, method = 'REML', data = model.data, control = con1)

anova(early.seral.rate.reml,early.seral.rate.reml.slope)

early.seral.rate<- lme(lambda.dift ~  core.early.seral.rate*matrix.early.seral.rate, random=~ 1|herd_name, method = 'ML', data = model.data, control = con1)
##Diagnostics
acf(residuals(early.seral.rate , type = 'normalized'),lag.max =10)#No issues
plot( fitted(early.seral.rate),residuals(early.seral.rate, type="normalized"))# variances are homogenous
abline(0,0, col = 'red')
cor(fitted(early.seral.rate.reml, level =0),model.data$lambda.dift) #0.8767
plot(model.data$lambda.dift~fitted(early.seral.rate))
abline(0,1, col = "red")
abline(0,0, col = "yellow")
summary(early.seral.rate)

#Rate model has higher correlation
anova(early.seral.per, early.seral.rate)
VarCorr(m0.d)
intervals(early.seral.rate)

```

#Percentage disturbed - includes only cutblocks and roads buffered by 50m
```{r, dist}
#---Percentage---
l.dist.per<- lme(l.lambda ~ core.dist.per*matrix.dist.per, random=~ 1|herd_name, method = 'ML', correlation = corAR1(0.5, form =~time|herd_name), data = model.data, control = con1)
acf(residuals(l.dist.per , type = 'normalized'),lag.max =10)#No issues
plot( fitted(l.dist.per),residuals(l.dist.per, type="normalized"))# variances are homogenous
abline(0,0, col = 'red')
cor(fitted(l.dist.per, level =0),model.data$l.lambda) #0.809
plot(model.data$l.lambda~fitted(l.dist.per, level =0))
abline(0,1, col = "red")
abline(0,0, col = "yellow")
summary(l.dist.per)

dist.per.reml<- lme(lambda.dift ~ core.dist.per*matrix.dist.per, random=~ 1|herd_name, method = 'REML', data = model.data, control = con1)
dist.per<- lme(lambda.dift ~ core.dist.per*matrix.dist.per, random=~ 1|herd_name, method = 'ML', data = model.data, control = con1)
acf(residuals(dist.per , type = 'normalized'),lag.max =10)#No issues
plot( fitted(dist.per),residuals(dist.per, type="normalized"))# variances are homogenous
abline(0,0, col = 'red')
cor(fitted(dist.per.reml, level =0),model.data$lambda.dift) #0.809
plot(model.data$lambda.dift~fitted(dist.per, level =1))
abline(0,1, col = "red")
abline(0,0, col = "yellow")
summary(dist.per)

#---Rate---
l.dist.rate<- lme(l.lambda ~ core.dist.rate*matrix.dist.rate, random=~ 1|herd_name,method = 'ML', correlation = corAR1(0.5, form =~time|herd_name), data = model.data, control = con1)
acf(residuals(l.dist.rate , type = 'normalized'),lag.max =10)#No issues
plot( fitted(l.dist.rate),residuals(l.dist.rate, type="normalized"))# variances are homogenous
abline(0,0, col = 'red')
cor(fitted(l.dist.rate, level =0),model.data$l.lambda) #0.876
plot(model.data$l.lambda~fitted(l.dist.rate, level =0))
abline(0,1, col = "red")
abline(0,0, col = "yellow")
summary(l.dist.rate)

dist.rate.reml<- lme(lambda.dift ~ core.dist.rate*matrix.dist.rate, random=~ 1|herd_name,method = 'REML', data = model.data, control = con1)
dist.rate<- lme(lambda.dift ~ core.dist.rate*matrix.dist.rate, random=~ 1|herd_name,method = 'ML', data = model.data, control = con1)
acf(residuals(dist.rate , type = 'normalized'),lag.max =10)#No issues
plot( fitted(dist.rate),residuals(dist.rate, type="normalized"))# variances are homogenous
abline(0,0, col = 'red')
cor(fitted(dist.rate.reml, level =0),model.data$lambda.dift) #0.876
plot(model.data$lambda.dift~fitted(dist.rate, level =1))
abline(0,1, col = "red")
abline(0,0, col = "yellow")
summary(dist.rate)

anova(dist.per, dist.rate)
```

#Disturbance including cutblocks and roads with buffering each by 500m
```{r, dist500}
#---Percentage---
l.dist500.per<- lme(l.lambda ~ core.dist500.per*matrix.dist500.per, random=~ 1|herd_name, method = 'ML', correlation = corAR1(0.5, form =~time|herd_name),data = model.data, control = con1)
acf(residuals(l.dist500.per, type = 'normalized'),lag.max =10)#No issues
plot( fitted(l.dist500.per),residuals(l.dist500.per, type="normalized"))# variances are homogenous
abline(0,0, col = 'red')
cor(fitted(l.dist500.per, level =1),model.data$l.lambda) #0.7786
plot(model.data$l.lambda~fitted(l.dist500.per))
abline(0,1, col = "red")
abline(0,0, col = "yellow")
summary(l.dist500.per)

dist500.per.reml<- lme(lambda.dift ~ core.dist500.per*matrix.dist500.per, random=~ 1|herd_name, method = 'REML', data = model.data, control = con1)

dist500.per<- lme(lambda.dift ~ core.dist500.per*matrix.dist500.per, random=~ 1|herd_name, method = 'ML', data = model.data, control = con1)
acf(residuals(dist500.per, type = 'normalized'),lag.max =10)#No issues
plot( fitted(dist500.per),residuals(dist500.per, type="normalized"))# variances are homogenous
abline(0,0, col = 'red')
cor(fitted(dist500.per, level =1),model.data$lambda.dift) #0.7786
plot(model.data$lambda.dift~fitted(dist500.per))
abline(0,1, col = "red")
abline(0,0, col = "yellow")
summary(dist500.per)

#---Rate---
l.dist500.rate<- lme(l.lambda ~ core.dist500.rate*matrix.dist500.rate,random=~ 1|herd_name, method = 'ML', correlation = corAR1(0.5, form =~time|herd_name), data = model.data, control = con1)
acf(residuals(l.dist500.rate , type = 'normalized'),lag.max =10)#No issues
plot( fitted(l.dist500.rate),residuals(l.dist500.rate, type="normalized"))# variances are homogenous
abline(0,0, col = 'red')
cor(fitted(l.dist500.rate, level =1),model.data$l.lambda) #0.86
plot(model.data$l.lambda~fitted(l.dist500.rate))
abline(0,1, col = "red")
abline(0,0, col = "yellow")
summary(l.dist500.rate)

dist500.rate.reml<- lme(lambda.dift ~ core.dist500.rate*matrix.dist500.rate,random=~ 1|herd_name, method = 'REML', data = model.data, control = con1)

dist500.rate<- lme(lambda.dift ~ core.dist500.rate*matrix.dist500.rate,random=~ 1|herd_name, method = 'ML', data = model.data, control = con1)
acf(residuals(dist500.rate , type = 'normalized'),lag.max =10)#No issues
plot( fitted(dist500.rate),residuals(dist500.rate, type="normalized"))# variances are homogenous
abline(0,0, col = 'red')
cor(fitted(dist500.rate.reml, level =0),model.data$lambda.dift) #0.86
plot(model.data$lambda.dift~fitted(dist500.rate))
abline(0,1, col = "red")
abline(0,0, col = "yellow")
summary(dist500.rate)

anova(dist500.per, dist500.rate)
```

## OVERALL
```{r, overall}
aic.values<-AIC(m0.b,early.seral.per,early.seral.rate,dist.per, dist.rate, dist500.per, dist500.rate)
aic.values$delta<-round(qpcR::akaike.weights(aic.values$AIC)$deltaAIC, 3)
aic.values$weights<-round(qpcR::akaike.weights(aic.values$AIC)$weights, 3)
aic.values
summary(m0.b)
getVarCov(m0.b)

summary(m0.b.reml)
intervals(m0.b.reml)
cor(fitted(m0.b.reml, level =0),model.data$lambda.dift) #0.7786

summary(early.seral.per.reml)
intervals(early.seral.per.reml)
cor(fitted(early.seral.per.reml, level =0),model.data$lambda.dift) #0.7786

summary(early.seral.rate.reml)
cor(fitted(early.seral.rate.reml, level =0),model.data$lambda.dift)

summary(dist.per.reml)
cor(fitted(dist.per.reml, level =0),model.data$lambda.dift)
summary(dist.rate.reml)
cor(fitted(dist.rate.reml, level =0),model.data$lambda.dift)

summary(dist500.per.reml)
cor(fitted(dist500.per.reml, level =0),model.data$lambda.dift)
summary(dist500.rate.reml)
cor(fitted(dist500.rate.reml, level =0),model.data$lambda.dift)
```
#FIGURE 3: observed vs predicted
```{r, obs_pred}
dtgx<-data.table(cbind(model.data[,c("lambda.dift", "herd_name")],fitted = fitted(dist500.rate.reml, level =1)))
dtgx[,type:='PInit']
dtgx2<-data.table(cbind(model.data[,c("lambda.dift","herd_name")],fitted = fitted(dist500.per.reml, level =1)))
dtgx2[,type:='PHab']

dtgx3<-rbind(dtgx,dtgx2)
dtgx3<-dtgx3[, herd_name:=lapply(.SD, function(x) { gsub("_", " ", x)}), .SDcols = "herd_name"]

dtgx3<-dtgx3[!lambda.dift > 0.4,]
ggplot(data = dtgx3, aes(y=lambda.dift, x =fitted, color = herd_name)) +
  facet_grid(type~.)+
  geom_point() +
  labs(y = "Observed", x = "Predicted")+
  geom_abline(intercept = 0, slope = 1) +
  theme_bw() +
  guides(color=guide_legend(title = "Herd")) 



```

#FIGURE 4. Behaviour of the model

```{r, behave}
bhv0<-data.table(matrix.dist500.rate=seq(-0.4,0.4, 0.02), core.dist500.rate = -0.1)
bhv1<-data.table(matrix.dist500.rate=seq(-0.4,0.4, 0.02), core.dist500.rate = 0)
bhv2<-data.table(matrix.dist500.rate=seq(-0.4,0.4, 0.02), core.dist500.rate = 0.1)
bhv3<-data.table(matrix.dist500.rate=seq(-0.4,0.4, 0.02), core.dist500.rate = 0.3)
bh<-rbindlist(list(bhv0,bhv1, bhv2, bhv3))
bh[, herd_id:= 1]

bh_herds<-data.table(herd_name=unique(model.data$herd_name), herd_id =1)
bh_herds2<-merge(bh_herds, bh, by.x="herd_id", by.y="herd_id", all=TRUE, allow= TRUE)

bh_herds2$pred<-predict(dist500.rate.reml, bh_herds2)
bh_herds2[core.dist500.rate == -0.1, core:='CR500 Core = -0.1']
bh_herds2[core.dist500.rate == 0, core:='CR500 Core = 0']
bh_herds2[core.dist500.rate == 0.1, core:='CR500 Core = 0.1']
bh_herds2[core.dist500.rate == 0.3, core:='CR500 Core = 0.3']

bh$pred<-predict(dist500.rate.reml, bh,level=0)
bh[core.dist500.rate == 0, core:='0']
bh[core.dist500.rate == 0.1, core:='0.1']
bh[core.dist500.rate == 0.3, core:='0.3']

bh_herds2[, herd_name:=lapply(.SD, function(x) { gsub("_", " ", x)}), .SDcols = "herd_name"]

fig4<-ggplot(data = bh_herds2,aes(x = matrix.dist500.rate, y = pred, color = herd_name)) +
  facet_grid(~core) +
  geom_line() +
  geom_abline(slope = 0, intercept = 0, color= "black") +
  theme_bw() +
  labs(y = expression(paste("Population trend ", hat(italic("r")))), x = "CR500 Matrix (% of initial survey (PInit))")+
  guides(color=guide_legend(title = "Herd"))
fig4

```

#GAMLSS
To be determined later
```{r, rsf, echo=FALSE, eval=FALE}
gam.dist500.per<-gamlss(l.lambda ~ core.burn40.per + matrix.burn40.per + re(random=~1|herd_name,method = "REML"), opt="optim",   sigma.formula = ~core.dist.per, family = NO(), data = model.data, control =gamlss.control(c.crit = 0.005), method=CG())
summary(gam.dist500.per)
```
