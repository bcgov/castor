---
title: "04_relationship_between_perimeter_size"
author: "Elizabeth Kleynhans"
date: "2024-10-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
require (sf)
require (RPostgreSQL)
require (rpostgis)
require (fasterize)
require (raster)
require (dplyr)
library(bcdata)
library(data.table)
source(here::here("R/functions/R_Postgres.R"))
```

## Description

Here I download the fire incident data that kyle used to fit his models and the fire burn severity data that FAIB produces then i correlated the size of the fire from the incident dataset to the actual area burned according to the severity data set. Initally I fit this data using a gamma distribution with the following formula P(burned_area) ~ Gamma(mu, theta); mu = f(Perimiter size). This model worked pretty well but occasionally it sampled a fire size that was larger than the perimeter size. In theory this should not be possible because the perimiter size created by BCWS should include both burned and unburned areas. Thus Peter suggested if us the difference between burned area and perimeter size so then on my second try i modeled the following:
P(X-Y) ~ Gamma(mu, theta); mu = f(X) where X= perimeter size and Y=observed area burned. However, again when we put this into fireCastor it occasionally sampled a value that was too large so taht the Current_size - predicted area to remove was a negative value. Then Kyle suggested changing it to a % so that we sample a % between 0 and 1. Ill change my adjustment factor to a percentage to remove and try and fit a new set of models using the Beta distribution. This distribution is bounded between zero and 1 so thats good.


# get fire perimeter data and combine with FRT
```{r}
# join fire ignition to fire_polygons
 fire_bounds_hist<-try(
   bcdc_query_geodata("WHSE_LAND_AND_NATURAL_RESOURCE.PROT_HISTORICAL_FIRE_POLYS_SP") %>%
     filter(FIRE_YEAR > 2014) %>%
     collect()
 )

# fire point ignition data that Kyle used in his models
ignit<-try(
  bcdc_query_geodata("WHSE_LAND_AND_NATURAL_RESOURCE.PROT_HISTORICAL_INCIDENTS_SP") %>%
    filter(FIRE_YEAR > 2014) %>%
    filter(FIRE_TYPE == "Fire") %>%
    collect()
)

fire_ignit_df<-ignit %>% select(FIRE_NUMBER, FIRE_YEAR, FIRE_CAUSE, CURRENT_SIZE) %>% st_drop_geometry()

fire_bounds_hist_df<-fire_bounds_hist %>% select(FIRE_NUMBER, FIRE_YEAR, FIRE_CAUSE, FIRE_SIZE_HECTARES) %>% st_drop_geometry()

# fire_severity<-try(
#   bcdc_query_geodata("WHSE_FOREST_VEGETATION.VEG_BURN_SEVERITY_SP") %>% collect()
# )

#get FRT
FRT<-getSpatialQuery("SELECT * FROM public.frt_canada")

#get provincial boundary for clipping the layers to the area of interest
prov.bnd <- st_read ( dsn = "T:\\FOR\\VIC\\HTS\\ANA\\PROJECTS\\CASTOR\\Data\\admin_boundaries\\province\\gpr_000b11a_e.shp", stringsAsFactors = T) # Read simple features from file or database, or retrieve layer names and their geometry type(s)
st_crs(prov.bnd) #Retrieve coordinate reference system from sf or sfc object
prov.bnd <- prov.bnd [prov.bnd$PRENAME == "British Columbia", ] 
crs(prov.bnd)# this one needs to be transformed to 3005
bc.bnd <- st_transform (prov.bnd, 3005) #Transform coordinate system
st_crs(bc.bnd)

#Clip FRT to BC boundary
frt_clipped<-st_intersection(bc.bnd, FRT)
#plot(st_geometry(frt_clipped), col=sf.colors(10,categorical=TRUE))
length(unique(frt_clipped$Cluster))
frt_sf<-st_as_sf(frt_clipped)

# note clipping the fire locations to the BC boundary removes a few ignition points in several of the years
ignit<-ignit[bc.bnd,] # making sure all fire ignitions have coordinates within BC
ignit<-st_as_sf(ignit) #convert to sf object
# join the ignition points to frt
ignit <- st_join(ignit, frt_sf)
table(is.na(ignit$Cluster))

fire_ignit_df<-ignit %>% select(FIRE_NUMBER, FIRE_YEAR, FIRE_CAUSE, CURRENT_SIZE, Cluster) %>% st_drop_geometry()
```

# Get Fire severity data
```{r}
# Get fire severity data. Download it in two sections because all of it at once is too big.
fire_severity_15_17<-try(
  bcdc_query_geodata("WHSE_FOREST_VEGETATION.VEG_BURN_SEVERITY_SP") %>% filter(FIRE_YEAR < 2018) %>% collect()
)
fire_severity_18<-try(
  bcdc_query_geodata("WHSE_FOREST_VEGETATION.VEG_BURN_SEVERITY_SP") %>% filter(FIRE_YEAR == 2018) %>% collect()
)

fire_severity_19_22<-try(
  bcdc_query_geodata("WHSE_FOREST_VEGETATION.VEG_BURN_SEVERITY_SP") %>% filter(FIRE_YEAR > 2018) %>% collect()
)

fire_severity_23<-try(
  bcdc_query_geodata("WHSE_FOREST_VEGETATION.VEG_BURN_SEVERITY_SAME_YR_SP") %>% filter(FIRE_YEAR > 2022) %>% collect()
)
fire_severity_23<-fire_severity_23 %>% select(id, FIRE_NUMBER:FEATURE_LENGTH_M, geometry) %>% rename(geom=geometry)


fire_severity<-rbind(fire_severity_15_17, fire_severity_18)
fire_severity<-rbind(fire_severity, fire_severity_19_22)
fire_severity<-fire_severity %>% select(id, FIRE_NUMBER:FEATURE_LENGTH_M, geometry) %>% rename(geom=geometry)
fire_severity<-rbind(fire_severity, fire_severity_23)
table(fire_severity$FIRE_YEAR)

#save fire_severity data set because it takes a while to download
st_write(fire_severity, "C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\data\\spread\\fire_severity_data_raw_2015_23.gpkg")


rm(fire_severity_15_17, fire_severity_18, fire_severity_19_22, fire_severity_23)
gc()
```


```{r}
# if you did the steps above and previously saved it then get that data now
fire_severity<-st_read("C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\data\\spread\\fire_severity_data_raw_2015_23.gpkg")

# pull out the areas that were actually burned and sum them up by fire number
fire_severity_summary<- fire_severity %>% filter(BURN_SEVERITY_RATING %in% c("High", "Medium", "Low")) %>%
  group_by(FIRE_NUMBER, FIRE_YEAR) %>%
  summarise(total_area_ha = sum(AREA_HA),
            total_area_sqm = sum(FEATURE_AREA_SQM))



fire_dat<-left_join(fire_severity_summary, fire_ignit_df, by=c("FIRE_NUMBER", "FIRE_YEAR"))
fire_bounds_hist[, geometry:=NULL]

fire_dat<-left_join(fire_dat, fire_bounds_hist_df, by=c("FIRE_NUMBER", "FIRE_YEAR"))

# Im here
fire_dat_dt<-data.table(fire_dat)


#fire_dat_dt2<-merge(fire_dat_dt, fire_bounds_hist_df, by=c("FIRE_NUMBER", "FIRE_YEAR"))

#Note that fire sizes less than 100ha are included in the dataset but only for the years 2015 and 2016 so remove these

x<-fire_dat_dt[CURRENT_SIZE<100,]
table(x$FIRE_YEAR)

fire_dat_dt3<-fire_dat_dt[FIRE_SIZE_HECTARES>=100,]
x1<-fire_dat_dt3[FIRE_SIZE_HECTARES<total_area_ha, ]
#fire_dat_dt3[CURRENT_SIZE<total_area_ha, total_area_ha:=CURRENT_SIZE]
fire_dat_dt3<-fire_dat_dt3[FIRE_SIZE_HECTARES>=total_area_ha, ]

fire_dat_dt3<-fire_dat_dt3[FIRE_SIZE_HECTARES>CURRENT_SIZE,CURRENT_SIZE:= FIRE_SIZE_HECTARES]
fire_dat_dt3[, c("FIRE_CAUSE.y","FIRE_SIZE_HECTARES"):=NULL]
table(fire_dat_dt3$Cluster)
fire_dat_dt3<-st_as_sf(fire_dat_dt3)
fire_dat_dt3<-fire_dat_dt3 %>% st_drop_geometry()

write.csv(fire_dat_dt3, "C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\data\\spread\\fire_severity_fire_size_2015_2023.csv")

fire_dat_dt3<-read.csv("C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\data\\spread\\fire_severity_fire_size_2015_2023.csv")

plot_dat<-fire_dat_dt3[, c("FIRE_YEAR", "total_area_ha")][,burn_group:="fire_sev"]
plot_dat<-plot_dat %>% rename(areaburn=total_area_ha)
plot_dat2<-fire_dat_dt3[, c("FIRE_YEAR", "CURRENT_SIZE")][,burn_group:="perim"]
plot_dat2<-plot_dat2 %>% rename(areaburn=CURRENT_SIZE)
plot_dat<-rbind(plot_dat, plot_dat2)
plot_dat$FIRE_YEAR<-as.factor(plot_dat$FIRE_YEAR)

ggplot(data=plot_dat, aes(x=FIRE_YEAR, y=areaburn, fill=burn_group)) +
  geom_boxplot() +
  ylim(0, 10000)
```

# attempt at fitting beta distribution

```{r}
fire_dat<-data.table(fire_dat_dt3[, c("total_area_ha", "CURRENT_SIZE", "Cluster")])
str(fire_dat)
fire_dat$Cluster<-as.factor(fire_dat$Cluster)
fire_dat[Cluster=="3", Cluster:="5"]
fire_dat[Cluster=="7", Cluster:="5"]
fire_dat[Cluster=="9", Cluster:="11"]
table(fire_dat$Cluster)
fire_dat$Cluster <- factor(fire_dat$Cluster, levels=c('13', '5', '10', '11', '12', '14', '15'))

fire_dat$prop<-fire_dat$total_area_ha/fire_dat$CURRENT_SIZE

hist(fire_dat$prop, breaks=20)

## Fit and compare some models
library(gamlss)
fire_dat2<-fire_dat[!is.na(prop),][prop<1,][!is.na(Cluster),]

m1<-gamlss(prop ~  log(CURRENT_SIZE) + Cluster,
           sigma.formula = ~ log(CURRENT_SIZE) + (Cluster), link = 'log', family = GB1(), 
           data = fire_dat2, control = gamlss.control(n.cyc = 3000))

wp(m1)
plot(m1)
summary(m1)

predicted<-predictAll(m1, newdata=fire_dat2)
fire_dat2$mu<-predicted$mu
fire_dat2$sigma<-predicted$sigma
fire_dat2$nu<-predicted$nu
fire_dat2$tau<-predicted$tau


fire_dat2[Cluster=="13", sigma_test:=(0.31491 + -0.15672*log(CURRENT_SIZE))]
fire_dat2[Cluster=="13", sigma_test:=exp(sigma_test)/(1+exp(sigma_test))]
fire_dat2[Cluster=="13"]

fire_dat2[Cluster=="13", mu_test:=(0.25107 + 0.06989*log(CURRENT_SIZE))]
fire_dat2[Cluster=="13", mu_test:= (exp(mu_test)/(1+exp(mu_test)))]

fire_dat2[Cluster=="13", fire_size_prop:= rGB1(1, mu=mu, sigma= sigma, nu=exp(nu), tau=exp(tau)), by=.I]




test.0.beta.intecept <- gamlss(prop_reduc ~ 1,
                 family = BE(),
                 data = na.omit(fire_dat2))
test.0.beta <- gamlss(prop_reduc ~ log(CURRENT_SIZE),
                 family = BE(),
                 data = na.omit(fire_dat2))
test.1.beta <- gamlss(prop_reduc ~ CURRENT_SIZE,
                 family = BE(),
                 data = na.omit(fire_dat2))
test.2.beta <- gamlss(prop_reduc ~ log(CURRENT_SIZE) + Cluster,
                 family = BE(),
                 data = na.omit(fire_dat2))
test.3.beta <- gamlss(prop_reduc ~ CURRENT_SIZE + Cluster,
                 family = BE(),
                 data = na.omit(fire_dat2))
test.4.beta <- gamlss(prop_reduc ~ log(CURRENT_SIZE) + Cluster,
                      sigma.formula = ~ log(CURRENT_SIZE),family = BE(),
                 data = na.omit(fire_dat2))
test.5.beta <- gamlss(prop_reduc ~ log(CURRENT_SIZE) + Cluster,
                      sigma.formula = ~ log(CURRENT_SIZE) +Cluster,family = BE(),
                 data = na.omit(fire_dat2))

test.6.GB1 <- gamlss(prop_reduc ~ 1,family = GB1(),
                 data = na.omit(fire_dat2), control = gamlss.control(n.cyc = 2000))
test.7.GB1 <- gamlss(prop_reduc ~ CURRENT_SIZE,family = GB1(),
                 data = na.omit(fire_dat2), control = gamlss.control(n.cyc = 2000))
test.8.GB1 <- gamlss(prop_reduc ~ Cluster,family = GB1(),
                 data = na.omit(fire_dat2), control = gamlss.control(n.cyc = 2000))
test.9.GB1 <- gamlss(prop_reduc ~ CURRENT_SIZE + Cluster,family = GB1(),
                 data = na.omit(fire_dat2), control = gamlss.control(n.cyc = 2000))
test.10.GB1 <- gamlss(prop_reduc ~ CURRENT_SIZE + Cluster,
                      sigma.formula = ~ CURRENT_SIZE,
                      family = GB1(),
                 data = na.omit(fire_dat2), control = gamlss.control(n.cyc = 2000))
test.10b.GB1 <- gamlss(prop_reduc ~ CURRENT_SIZE + Cluster,
                      sigma.formula = ~ Cluster,
                      family = GB1(),
                 data = na.omit(fire_dat2), control = gamlss.control(n.cyc = 2000))
test.11.GB1 <- gamlss(prop_reduc ~ CURRENT_SIZE + Cluster,
                      sigma.formula = ~ CURRENT_SIZE +Cluster,
                      family = GB1(),
                 data = na.omit(fire_dat2), control = gamlss.control(n.cyc = 2000))
test.12.GB1 <- gamlss(prop_reduc ~ log(CURRENT_SIZE) + Cluster,
                      sigma.formula = ~ CURRENT_SIZE +Cluster,
                      family = GB1(),
                 data = na.omit(fire_dat2), control = gamlss.control(n.cyc = 2000))
test.13.GB1 <- gamlss(prop_reduc ~ log(CURRENT_SIZE) + Cluster,
                      sigma.formula = ~ log(CURRENT_SIZE) +Cluster,
                      family = GB1(),
                 data = na.omit(fire_dat2), control = gamlss.control(n.cyc = 2000))
predicted<-predictAll(test.13.GB1, newdata = fire_dat2[,c("CURRENT_SIZE", "Cluster")], type="response")

fire_dat2$mu<-predicted$mu
fire_dat2$sigma <- predicted$sigma
fire_dat2$nu <- predicted$nu
fire_dat2$tau <- predicted$tau
fire_dat2$mean <- with(predicted, qGB1(0.5, mu = mu, sigma = sigma, nu = nu, tau=tau))

plot(x=fire_dat2$mu, y=fire_dat2$prop_reduc, xlim=c(0,0.6))
abline(a=0,b=1)

ggplot(data=fire_dat2, aes(x=mu, y=prop_reduc))+
  geom_point() +
  geom_abline(intercept=0, slope=1) +
  geom_smooth(method='loess', formula= y~x, col="red") +
  labs(x='Predicted Values', y='Actual Values', title='Predicted vs. Actual Values')

  



GAIC(test.0.beta.intecept, test.0.beta,test.1.beta,test.2.beta,test.3.beta, test.4.beta, test.5.beta, test.6.GB1,test.7.GB1,test.8.GB1,test.9.GB1,test.10.GB1,test.11.GB1,test.12.GB1, test.13.GB1, test.10b.GB1, m1)

plot(test.5.beta)
wp(test.5.beta, ylim.all=TRUE)
summary(test.5.beta)


# try truncated gamma distribution
library(gamlss.tr)
gen.trun(par=fire_dat2$CURRENT_SIZE, family="GA", name="currentSize", type="right", varying = TRUE)

m1<-gamlss(diff_size ~CURRENT_SIZE , family="GAcurrentSize", data= fire_dat2)
m2<-gamlss(diff_size ~CURRENT_SIZE +Cluster, family="GAcurrentSize", data= fire_dat2)

wp(m2)
GAIC(m1,m2)

plot(test.11.GB1)
wp(test.13.GB1)


```


# try leaving out 25% of the data and test the model on that 
```{r}
set.seed(222)
ind <- sample(2, nrow(fire_dat2), replace = TRUE, prob = c(0.75, 0.25))
train <- fire_dat2[ind==1,]
table(train$Cluster)
test <- data.table(fire_dat2[ind==2,])
table(test$Cluster)

test1<-test[,c("CURRENT_SIZE", "Cluster")]


top_mod <- gamlss(prop ~ log(CURRENT_SIZE) + Cluster,
                      sigma.formula = ~ log(CURRENT_SIZE)+Cluster,
                  link = 'log',
                  family = GB1(),
                 data = na.omit(train), control = gamlss.control(n.cyc = 2000))
wp(top_mod)


predicted<- predictAll(m1, newdata = na.omit(test[test$total_area_ha>0,]))
test<-test[!is.na(CURRENT_SIZE),][!is.na(Cluster),]
test$mu <- predicted$mu
test$sigma <- predicted$sigma
test$nu <- predicted$nu
test$tau <- predicted$tau

test$frt_5 <- ifelse(test$Cluster == 5, 1, 0)
test$frt_7 <- ifelse(test$Cluster == 7, 1, 0)
test$frt_9 <- ifelse(test$Cluster == 9, 1, 0)
test$frt_10 <- ifelse(test$Cluster == 10, 1, 0)
test$frt_11 <- ifelse(test$Cluster == 11, 1, 0)
test$frt_12 <- ifelse(test$Cluster == 12, 1, 0)
test$frt_13 <- ifelse(test$Cluster == 13, 1, 0)
test$frt_14 <- ifelse(test$Cluster == 14, 1, 0)
test$frt_15 <- ifelse(test$Cluster == 15, 1, 0)

test[,sigma_test:=exp(m1$sigma.coefficients[1] + log(CURRENT_SIZE)* m1$sigma.coefficients[2] + frt_5 * m1$sigma.coefficients[3] + frt_10 * m1$sigma.coefficients[6] + frt_11 * m1$sigma.coefficients[7] + frt_12 * m1$sigma.coefficients[8] + frt_13 * m1$sigma.coefficients[9] + frt_14 * m1$sigma.coefficients[10])]

  
test[,mu_test := top_mod$mu.coefficients[1] + 
  log(CURRENT_SIZE)*top_mod$mu.coefficients[2] + frt_5 * top_mod$mu.coefficients[3] + frt_10 * top_mod$mu.coefficients[6] + frt_11 * top_mod$mu.coefficients[7] + frt_12 * top_mod$mu.coefficients[8] + frt_13 * top_mod$mu.coefficients[9] + frt_14*top_mod$mu.coefficients[10]]

test$mean <- with(predicted, qGB1(0.5, mu = mu, sigma = sigma, nu = nu, tau=tau))
test$upper.2 <- with(predicted, qGB1(0.95, mu = mu, sigma = sigma, nu = nu, tau=tau))
test$lower.2 <- with(predicted, qGB1(0.05, mu = mu, sigma = sigma, nu = nu, tau=tau))
test$upper.1 <- with(predicted, qGB1(0.67, mu = mu, sigma = sigma, nu = nu, tau=tau))
test$lower.1 <- with(predicted, qGB1(0.33, mu = mu, sigma = sigma, nu = nu, tau=tau))

# Plot it
p.min <-
  ggplot(test, aes(x = CURRENT_SIZE , y = prop) ) +
  geom_point(alpha=0.4) +
  #facet_wrap(~ ForestQualityClass) +
  xlab(expression(paste("Perimeter size, ha"))) +
  ylab(expression(paste("proportion to remove"))) +
  geom_line(aes(y = mean, x = CURRENT_SIZE), color = 'blue', data = test, lwd = 1) +
  geom_line(aes(y = lower.2, x =  CURRENT_SIZE), linetype = "dashed", color = 'red', data = test) +
  geom_line(aes(y = upper.2 , x =  CURRENT_SIZE), linetype = "dashed", color = 'red', data = test) +
  geom_line(aes(y = lower.1 , x =  CURRENT_SIZE), linetype = "dotted", color = 'blue', data = test) +
  geom_line(aes(y = upper.1 , x =  CURRENT_SIZE), linetype = "dotted", color = 'blue', data = test) +
  facet_wrap(~Cluster, scales="free")

 ggplot(test, aes(x = prop_reduc , y = mu) ) +
  geom_point(alpha=0.4)+
    xlab(expression(paste("observed"))) +
  ylab(expression(paste("predicted"))) +
   xlim(0, 0.7) + ylim(0,0.7) +
    geom_abline(intercept =0, slope=1, col ="green")+
  facet_wrap(~Cluster)
```



# previous attempt at fitting gamma distribution 


Below Im going to try do what Kyle did in params/linkHBS_VRI_Calibration.Rmd. Here he fits a gamma and negative binomial model using gamls to correlate observed wood volume to projected volume. Im going to try the same methods to fit area burned i.e. difference between perimeter size and total area in a fire that was observed to burn at low, medium or high intensity to the perimeter size of the fire. Im also going to test wheterh adding fire regime type helps the fit of this model. But first I look at a straighforward linear model. Note when you do this it looks like the variance increases as the mean increases
```{r}
fire_dat_dt3$Cluster<-as.factor(fire_dat_dt3$Cluster)
model1 <- lm(diff_size ~ CURRENT_SIZE, data=fire_dat)
summary(model1)
plot(model1)
area_var <- predict(model1, data =fire_dat, interval="prediction")
init.data <- cbind(fire_dat, area_var)

lm_eqn = function(m) {
  l <- list(a = format(as.numeric(coef(m)[1]), digits = 2),
      b = format(as.numeric(coef(m)[2]), digits = 2),
      r2 = format(summary(m)$r.squared, digits = 3))
  eq <- substitute(italic(y) == a + b %.% italic(x)*","~~italic(r)^2~"="~r2,l)
  as.character(as.expression(eq))                 
}

ggplot(init.data , aes(CURRENT_SIZE, diff_size)) +
  geom_point() +
  geom_smooth(method='lm', se = TRUE)+
  geom_line(aes(y=lwr), color = "red", linetype = "dashed")+
  geom_line(aes(y=upr), color = "red", linetype = "dashed") +
  theme_bw()



```

# Now try a gamma and lognormal distributed model
```{r}
## Fit and compare some models
library(gamlss)

fire_dat<-fire_dat_dt3[, c("total_area_ha", "CURRENT_SIZE", "Cluster")]
fire_dat$diff_size<-fire_dat$CURRENT_SIZE - fire_dat$total_area_ha
fire_dat$diff_size<-fire_dat$diff_size+0.01
fire_dat<-fire_dat[!is.na(Cluster),]
str(fire_dat)

fire_dat[Cluster=="3", Cluster:="5"]
fire_dat[Cluster=="7", Cluster:="5"]
fire_dat[Cluster=="9", Cluster:="11"]
table(fire_dat$Cluster)

test.0.gamma <- gamlss(diff_size ~ CURRENT_SIZE,
                 sigma.formula = ~ 1,
                 mu.link = "log",
                 sigma.link = "log",
                 family = GA(),
                 data = fire_dat,
                 control = gamlss.control(n.cyc = 2000))
test.0.gamma2 <- gamlss(diff_size ~ CURRENT_SIZE+Cluster,
                 sigma.formula = ~ 1,
                 mu.link = "log",
                 sigma.link = "log",
                 family = GA(),
                 data = fire_dat,
                 control = gamlss.control(n.cyc = 2000))

test.0.lognor <- gamlss(diff_size ~ CURRENT_SIZE,
                 sigma.formula = ~ 1,
                 mu.link = "log",
                 sigma.link = "log",
                 family = LOGNO(),
                 data = fire_dat,
                 control = gamlss.control(n.cyc = 2000))
test.0.lognor2 <- gamlss(diff_size ~ CURRENT_SIZE+Cluster,
                 sigma.formula = ~ 1,
                 mu.link = "log",
                 sigma.link = "log",
                 family = LOGNO(),
                 data = fire_dat,
                 control = gamlss.control(n.cyc = 2000))
AIC(test.0.gamma,test.0.gamma2, test.0.lognor, test.0.lognor2)

# ok try a gamma distributed model with som added complexities e.g log Current size and Cluster (frt)
test.1.gamma <- gamlss(diff_size ~ log(CURRENT_SIZE),
                 sigma.formula = ~ 1,
                 sigma.link = "log",
                 family = GA(),
                 data = fire_dat)
test.1.gamma2 <- gamlss(diff_size ~ log(CURRENT_SIZE)+Cluster,
                 sigma.formula = ~ 1,
                 sigma.link = "log",
                 family = GA(),
                 data = fire_dat)

test.1.lognor <- gamlss(diff_size ~ log(CURRENT_SIZE),
                 sigma.formula = ~ 1,
                 mu.link = "log",
                 sigma.link = "log",
                 family = LOGNO(),
                 data = fire_dat)
test.1.lognor2 <- gamlss(diff_size ~ log(CURRENT_SIZE)+Cluster,
                 sigma.formula = ~ 1,
                 mu.link = "log",
                 sigma.link = "log",
                 family = LOGNO(),
                 data = fire_dat)

test.0.gam.inv <- gamlss(diff_size ~ CURRENT_SIZE+Cluster,
                 sigma.formula = ~ 1,
                 mu.link = "inverse",
                 sigma.link = "inverse",
                 family = GA(),
                 data = fire_dat,
                 control = gamlss.control(n.cyc = 2000))

GAIC(test.0.gamma,test.0.gamma2, test.0.lognor, test.0.lognor2, test.1.gamma,test.1.gamma2, test.1.lognor, test.1.lognor2, test.0.gam.inv)


# non of these are great. What about if I let the sigma be a function of the Current size

test.2 <- gamlss(diff_size ~ CURRENT_SIZE+Cluster,
                 sigma.formula = ~ CURRENT_SIZE,
                 sigma.link = "log",
                 family = GA(),
                 data = fire_dat,
                 control = gamlss.control(n.cyc = 2000))
wp(test.2)

test.3 <- gamlss(diff_size ~ log(CURRENT_SIZE),
                 sigma.formula = ~ log(CURRENT_SIZE)+Cluster,
                 sigma.link = "log",
                 family = GA(),
                 data = fire_dat,
                 control = gamlss.control(n.cyc = 2000))
test.4 <- gamlss(diff_size ~ CURRENT_SIZE,
                 sigma.formula = ~ CURRENT_SIZE + Cluster,
                 sigma.link = "log",
                 family = GA(),
                 data = na.omit(fire_dat),
                 control = gamlss.control(n.cyc = 2000))
test.5 <- gamlss(diff_size ~ log(CURRENT_SIZE) +Cluster,
                 sigma.formula = ~ log(CURRENT_SIZE)+Cluster,
                 sigma.link = "log",
                 family = GA(),
                 data = na.omit(fire_dat),
                 control = gamlss.control(n.cyc = 2000))

test.6 <- gamlss(diff_size ~ log(CURRENT_SIZE) +Cluster,
                 family = IG(),
                 data = na.omit(fire_dat),
                 control = gamlss.control(n.cyc = 2000))


m3<-gamlss(diff_size~log(CURRENT_SIZE)+Cluster,data=fire_dat,family=GAF, method=mixed(1,300),
c.crit=0.00001)

wp(test.3)
wp(test.5, ylim.all=TRUE)
wp(m3)
plot(test.3)
plot(test.5)
GAIC(test.0.gamma,test.0.gamma2, test.0.lognor, test.0.lognor2, test.1.gamma,test.1.gamma2, test.1.lognor, test.1.lognor2, test.0.gam.inv, test.3, test.2, test.4, test.5,m3, test.6)


predicted<-predictAll(test.5, newdata = fire_dat2[,c("CURRENT_SIZE", "Cluster")], type="response")

fire_dat2$mu<-predicted$mu
fire_dat2$sigma <- predicted$sigma
fire_dat2$mean <- with(predicted, qGA(0.5, mu = mu, sigma = sigma))

plot(x=fire_dat2$mu, y=fire_dat2$diff_size, xlim=c(0,0.6))
abline(a=0,b=1)

ggplot(data=fire_dat2, aes(x=mu, y=diff_size))+
  geom_point() +
  geom_abline(intercept=0, slope=1) +
  geom_smooth(method='lm', formula= y~x, col="red") +
  labs(x='Predicted Values', y='Actual Values', title='Predicted vs. Actual Values')

```

# Test for spatial autocorrelation
Below i check that the points are independently distributed in space i.e. that there is no spatial auto corrleation i.e. that im over estimating or under estimating the values and that there is a spatial trend to this estimate. 
```{r}
ind.1<- predictAll(test.5, newdata = fire_dat)
mu<-ind.1$mu
ind.2<-cbind(fire_dat, mu)
ind.2$res<-ind.2$diff_size - ind.2$mu
#ind.2<- st_as_sf(ind.2) %>% st_cast("POLYGON")

ind.2$centroids <-st_centroid(st_buffer(st_sfc(ind.2$geom), 0))

coords<-st_coordinates(ind.2$centroids)

#get distances

dists <- as.matrix(dist(coords))
dists.inv <- 1/dists 
diag(dists.inv) <- 0
#dists[1:50, 1:50] # check what they look like - units are in metres

#auto.2$res<-auto.2$res+runif(326, 1, 10000)
library(ape)
Moran.I(ind.2$res, dists.inv)
#The P value is not significant its 0.8 this suggests that we cant reject the null hypothesis i.e. that the points are randomly distributed. Good! This also appears to be true when we plot it. see blow.

xyspatial=SpatialPoints(coords)
porspatial=data.frame(ind.2$res)
spatialdata=SpatialPointsDataFrame(xyspatial,porspatial)

library(gstat)
vario2 <- variogram(ind.2$res~1, spatialdata)
plot(vario2)

bubble(spatialdata, "ind.2.res", col = c("blue", "orange"), main = "Residuals", xlab = "X-coordinates", 
    ylab = "Y-coordinates")
```

#fit independent data to test it
Now Im going to test how well my values are predicted. Ill fit the model to 75% of the data and test it on 25% of the data. 


```{r}
set.seed(222)
ind <- sample(2, nrow(fire_dat), replace = TRUE, prob = c(0.80, 0.20))
train <- fire_dat[ind==1,]
table(train$Cluster)
test <- data.table(fire_dat[ind==2,])
#test[, geom:=NULL]

test1<-test[,c("CURRENT_SIZE", "Cluster")]

top_mod <- gamlss(diff_size ~ log(CURRENT_SIZE) +Cluster,
                 sigma.formula = ~ log(CURRENT_SIZE)+Cluster,
                 sigma.link = "log",
                 family = GA(),
                 data = na.omit(train))

predicted<- predictAll(top_mod, newdata = test)

test$mu <- predicted$mu
test$sigma <- predicted$sigma
test$upper.2 <- with(predicted, qGA(0.95, mu = mu, sigma = sigma))
test$lower.2 <- with(predicted, qGA(0.05, mu = mu, sigma = sigma))
test$upper.1 <- with(predicted, qGA(0.67, mu = mu, sigma = sigma))
test$lower.1 <- with(predicted, qGA(0.33, mu = mu, sigma = sigma))

# Plot it
p.min <-
  ggplot(test, aes(x = CURRENT_SIZE , y = diff_size ) ) +
  geom_point(alpha=0.4) +
  #facet_wrap(~ ForestQualityClass) +
  xlab(expression(paste("Perimeter size, ha"))) +
  ylab(expression(paste("Observed area burned, ha"))) +
  geom_line(aes(y = mu, x = CURRENT_SIZE), color = 'blue', data = test, lwd = 1) +
  geom_line(aes(y = lower.2, x =  CURRENT_SIZE), linetype = "dashed", color = 'red', data = test) +
  geom_line(aes(y = upper.2 , x =  CURRENT_SIZE), linetype = "dashed", color = 'red', data = test) +
  geom_line(aes(y = lower.1 , x =  CURRENT_SIZE), linetype = "dotted", color = 'blue', data = test) +
  geom_line(aes(y = upper.1 , x =  CURRENT_SIZE), linetype = "dotted", color = 'blue', data = test) +
  facet_wrap(~Cluster, scales="free") 




# now trying with a dummy dataset

CURRENT_SIZE<- rep(seq(100,  1000000, by = 1000), 9)
Cluster<-rep(c(5,7,9,10,11,12,13,14,15), each = 9000)

sim_dat<-data.frame(cbind(CURRENT_SIZE, Cluster))
sim_dat$frt_5 <- ifelse(sim_dat$Cluster == 5, 1, 0)
sim_dat$frt_7 <- ifelse(sim_dat$Cluster == 7, 1, 0)
sim_dat$frt_9 <- ifelse(sim_dat$Cluster == 9, 1, 0)
sim_dat$frt_10 <- ifelse(sim_dat$Cluster == 10, 1, 0)
sim_dat$frt_11 <- ifelse(sim_dat$Cluster == 11, 1, 0)
sim_dat$frt_12 <- ifelse(sim_dat$Cluster == 12, 1, 0)
sim_dat$frt_13 <- ifelse(sim_dat$Cluster == 13, 1, 0)
sim_dat$frt_14 <- ifelse(sim_dat$Cluster == 14, 1, 0)
sim_dat$frt_15 <- ifelse(sim_dat$Cluster == 15, 1, 0)

new.dist.min <- predictAll(top_mod, newdata = sim_dat[,c("CURRENT_SIZE", "Cluster")])
sim_dat$mu <- new.dist.min$mu
sim_dat$sigma <- new.dist.min$sigma
sim_dat$upper.2 <- with(new.dist.min, qGA(0.95, mu = mu, sigma = sigma))
sim_dat$lower.2 <- with(new.dist.min, qGA(0.05, mu = mu, sigma = sigma))
sim_dat$upper.1 <- with(new.dist.min, qGA(0.67, mu = mu, sigma = sigma))
sim_dat$lower.1 <- with(new.dist.min, qGA(0.33, mu = mu, sigma = sigma))


p.min <-
  ggplot(sim_dat, aes(x = CURRENT_SIZE, y = mu) ) +
  geom_point(alpha=0.4) +
  #facet_wrap(~ ForestQualityClass) +
  xlab(expression(paste("Projected Volume Yield ", m^3, ")"))) +
  ylab(expression(paste("Observed Volume Yield ", m^3, ")"))) +
  geom_line(aes(y = mu, x = CURRENT_SIZE), color = 'blue', data = sim_dat, lwd = 1.75) +
  geom_line(aes(y = lower.2, x =CURRENT_SIZE  ), linetype = "dashed", color = 'red', data = sim_dat) +
  geom_line(aes(y = upper.2 , x =  CURRENT_SIZE), linetype = "dashed", color = 'red', data = sim_dat) +
  geom_line(aes(y = lower.1 , x =  CURRENT_SIZE), linetype = "dotted", color = 'blue', data = sim_dat) +
  geom_line(aes(y = upper.1 , x =  CURRENT_SIZE), linetype = "dotted", color = 'blue', data = sim_dat) +
  ylim(0,200000) + facet_wrap(~Cluster)



sigma=top_mod$sigma.coefficients[1] +
  log(sim_dat$CURRENT_SIZE)* top_mod$sigma.coefficients[2] +
  sim_dat$frt_5 * top_mod$sigma.coefficients[3] +
  sim_dat$frt_7 * top_mod$sigma.coefficients[4] +
  sim_dat$frt_9 * top_mod$sigma.coefficients[5] + 
  sim_dat$frt_10 * top_mod$sigma.coefficients[6] +
  sim_dat$frt_11 * top_mod$sigma.coefficients[7] +
  sim_dat$frt_12 * top_mod$sigma.coefficients[8] +
  sim_dat$frt_13 * top_mod$sigma.coefficients[9] +
  sim_dat$frt_14 * top_mod$sigma.coefficients[10] +
  sim_dat$frt_15 * top_mod$sigma.coefficients[11]
  
  
mu = coef(top_mod)[1] + 
  log(sim_dat$CURRENT_SIZE)*coef(top_mod)[2] +
  

x<-rGA(100, mu=sim_dat$mu[1], sigma=sim_dat$sigma[1])

# ok this seems to work.

hist(x)



```

Double check that how Im get the values off the distribution are correct
```{r}
test1<-test[,c("CURRENT_SIZE", "Cluster")]

top_mod <- gamlss(total_area_ha ~ log(CURRENT_SIZE) + Cluster,
                 sigma.formula = ~ log(CURRENT_SIZE) + Cluster,
                 sigma.link = "log",
                 family = GA(),
                 data = train,
                 control = gamlss.control(n.cyc = 2000))

predicted<- predictAll(top_mod, newdata = test1)

test$mu <- predicted$mu
test$sigma <- predicted$sigma
test$upper.2 <- with(predicted, qGA(0.95, mu = mu, sigma = sigma))
test$lower.2 <- with(predicted, qGA(0.05, mu = mu, sigma = sigma))
test$upper.1 <- with(predicted, qGA(0.67, mu = mu, sigma = sigma))
test$lower.1 <- with(predicted, qGA(0.33, mu = mu, sigma = sigma))

test[,frt_5:=0][Cluster=="5",frt_5:=1]
test[Cluster=="3",frt_5:=1]
test[Cluster=="7",frt_5:=1]
#test[,frt_7:=0][Cluster=="7",frt_7:=1]
#test[,frt_9:=0][Cluster=="9",frt_9:=1]
test[,frt_10:=0][Cluster=="10",frt_10:=1]
test[,frt_11:=0][Cluster=="11",frt_11:=1]
test[Cluster=="9",frt_11:=1]
test[,frt_12:=0][Cluster=="12",frt_12:=1]
test[,frt_13:=0][Cluster=="13",frt_13:=1]
test[,frt_14:=0][Cluster=="14",frt_14:=1]
test[,frt_15:=0][Cluster=="15",frt_15:=1]


test[,sigma_test:=exp(top_mod$sigma.coefficients[1] + log(CURRENT_SIZE)* top_mod$sigma.coefficients[2] + frt_5 * top_mod$sigma.coefficients[3] + frt_7 * top_mod$sigma.coefficients[4] + frt_9 * top_mod$sigma.coefficients[5] + frt_10 * top_mod$sigma.coefficients[6] + frt_11 * top_mod$sigma.coefficients[7] + frt_12 * top_mod$sigma.coefficients[8] + frt_13 * top_mod$sigma.coefficients[9] + frt_14 * top_mod$sigma.coefficients[10] + frt_15 * top_mod$sigma.coefficients[11])]
  
  
test[,mu_test := exp(top_mod$mu.coefficients[1] + 
  log(CURRENT_SIZE)*top_mod$mu.coefficients[2] + frt_5 * top_mod$mu.coefficients[3] + frt_10 * top_mod$mu.coefficients[6] + frt_11 * top_mod$mu.coefficients[7] + frt_12 * top_mod$mu.coefficients[8] + frt_13 * top_mod$mu.coefficients[9] + frt_14*top_mod$mu.coefficients[10])]



```


