---
title: "03_spread_data_prep"
author: "Elizabeth Kleynhans"
date: "2024-10-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
require (sf)
require (RPostgreSQL)
require (rpostgis)
require (fasterize)
require (raster)
require (dplyr)
library(bcdata)
library(data.table)
source(here::here("R/functions/R_Postgres.R"))
```

## Description

Here I download the fire incident data that kyle used to fit his models and the fire burn severity data that FAIB produces then i correlated the size of the fire from the incident dataset to the actual area burned according to the severity data set. I use the slope and se from this correlation to change the size of the fire that I use in my spread2 function.
```{r}
# join fire ignition to fire_polygons
 fire_bounds_hist<-try(
   bcdc_query_geodata("WHSE_LAND_AND_NATURAL_RESOURCE.PROT_HISTORICAL_FIRE_POLYS_SP") %>%
     filter(FIRE_YEAR > 2014) %>%
     collect()
 )

# fire point ignition data that Kyle used in his models
ignit<-try(
  bcdc_query_geodata("WHSE_LAND_AND_NATURAL_RESOURCE.PROT_HISTORICAL_INCIDENTS_SP") %>%
    filter(FIRE_YEAR > 2014) %>%
    filter(FIRE_TYPE == "Fire") %>%
    collect()
)

fire_ignit_df<-ignit %>% select(FIRE_NUMBER, FIRE_YEAR, FIRE_CAUSE, CURRENT_SIZE) %>% st_drop_geometry()

#fire_bounds_hist_df<-fire_bounds_hist %>% select(FIRE_NUMBER, FIRE_YEAR, FIRE_CAUSE, FIRE_SIZE_HECTARES) %>% st_drop_geometry()

# fire_severity<-try(
#   bcdc_query_geodata("WHSE_FOREST_VEGETATION.VEG_BURN_SEVERITY_SP") %>% collect()
# )

#get FRT
FRT<-getSpatialQuery("SELECT * FROM public.frt_canada")

#get provincial boundary for clipping the layers to the area of interest
prov.bnd <- st_read ( dsn = "T:\\FOR\\VIC\\HTS\\ANA\\PROJECTS\\CASTOR\\Data\\admin_boundaries\\province\\gpr_000b11a_e.shp", stringsAsFactors = T) # Read simple features from file or database, or retrieve layer names and their geometry type(s)
st_crs(prov.bnd) #Retrieve coordinate reference system from sf or sfc object
prov.bnd <- prov.bnd [prov.bnd$PRENAME == "British Columbia", ] 
crs(prov.bnd)# this one needs to be transformed to 3005
bc.bnd <- st_transform (prov.bnd, 3005) #Transform coordinate system
st_crs(bc.bnd)

#Clip FRT to BC boundary
frt_clipped<-st_intersection(bc.bnd, FRT)
#plot(st_geometry(frt_clipped), col=sf.colors(10,categorical=TRUE))
length(unique(frt_clipped$Cluster))
frt_sf<-st_as_sf(frt_clipped)

# note clipping the fire locations to the BC boundary removes a few ignition points in several of the years
ignit<-ignit[bc.bnd,] # making sure all fire ignitions have coordinates within BC
ignit<-st_as_sf(ignit) #convert to sf object
# join the ignition points to frt
ignit <- st_join(ignit, frt_sf)
table(is.na(ignit$Cluster))

fire_ignit_df<-ignit %>% select(FIRE_NUMBER, FIRE_YEAR, FIRE_CAUSE, CURRENT_SIZE, Cluster) %>% st_drop_geometry()
```

# Get Fire severity data
```{r}
# Get fire severity data. Download it in two sections because all of it at once is too big.
fire_severity_15_17<-try(
  bcdc_query_geodata("WHSE_FOREST_VEGETATION.VEG_BURN_SEVERITY_SP") %>% filter(FIRE_YEAR < 2018) %>% collect()
)
fire_severity_18<-try(
  bcdc_query_geodata("WHSE_FOREST_VEGETATION.VEG_BURN_SEVERITY_SP") %>% filter(FIRE_YEAR == 2018) %>% collect()
)

fire_severity_19_22<-try(
  bcdc_query_geodata("WHSE_FOREST_VEGETATION.VEG_BURN_SEVERITY_SP") %>% filter(FIRE_YEAR > 2018) %>% collect()
)

fire_severity_23<-try(
  bcdc_query_geodata("WHSE_FOREST_VEGETATION.VEG_BURN_SEVERITY_SAME_YR_SP") %>% filter(FIRE_YEAR > 2022) %>% collect()
)
fire_severity_23<-fire_severity_23 %>% select(id, FIRE_NUMBER:FEATURE_LENGTH_M, geometry) %>% rename(geom=geometry)


fire_severity<-rbind(fire_severity_15_17, fire_severity_18)
fire_severity<-rbind(fire_severity, fire_severity_19_22)
fire_severity<-fire_severity %>% select(id, FIRE_NUMBER:FEATURE_LENGTH_M, geometry) %>% rename(geom=geometry)
fire_severity<-rbind(fire_severity, fire_severity_23)
table(fire_severity$FIRE_YEAR)

#save fire_severity data set because it takes a while to download
st_write(fire_severity, "C:\\Work\\caribou\\castor_data\\Fire\\Fire_sim_data\\data\\spread\\fire_severity_data_raw_2015_23.gpkg")


rm(fire_severity_15_17, fire_severity_18, fire_severity_19_22, fire_severity_23)
gc()


# pull out the areas that were actually burned and sum them up by fire number
fire_severity_summary<- fire_severity %>% filter(BURN_SEVERITY_RATING %in% c("High", "Medium", "Low")) %>%
  group_by(FIRE_NUMBER, FIRE_YEAR) %>%
  summarise(total_area_ha = sum(AREA_HA),
            total_area_sqm = sum(FEATURE_AREA_SQM))



fire_dat<-left_join(fire_severity_summary, fire_ignit_df, by=c("FIRE_NUMBER", "FIRE_YEAR"))

table(fire_dat$FIRE_YEAR)

# Im here
fire_dat_dt<-data.table(fire_dat)
#fire_dat_dt2<-merge(fire_dat_dt, fire_bounds_hist_df, by=c("FIRE_NUMBER", "FIRE_YEAR"))

#Note that fire sizes less than 100ha are included in the dataset but only for the years 2015 and 2016 so remove these

x<-fire_dat_dt[CURRENT_SIZE<100,]
table(x$FIRE_YEAR)

fire_dat_dt3<-fire_dat_dt[CURRENT_SIZE>=100,]
fire_dat_dt3<-fire_dat_dt3[CURRENT_SIZE>=total_area_ha, ]
table(fire_dat_dt3$Cluster)

plot_dat<-fire_dat_dt3[, c("FIRE_YEAR", "total_area_ha")][,burn_group:="fire_sev"]
plot_dat<-plot_dat %>% rename(areaburn=total_area_ha)
plot_dat2<-fire_dat_dt3[, c("FIRE_YEAR", "CURRENT_SIZE")][,burn_group:="perim"]
plot_dat2<-plot_dat2 %>% rename(areaburn=CURRENT_SIZE)
plot_dat<-rbind(plot_dat, plot_dat2)
plot_dat$FIRE_YEAR<-as.factor(plot_dat$FIRE_YEAR)

ggplot(data=plot_dat, aes(x=FIRE_YEAR, y=areaburn, fill=burn_group)) +
  geom_boxplot() +
  ylim(0, 10000)
```

# attempt at fitting gamma distribution 
```{r}
library(lme4)
fire_dat_dt3[FIRE_NUMBER=="G91933",CURRENT_SIZE:=FIRE_SIZE_HECTARES]
fire_dat_dt3[222]
fire_dat_dt3<-fire_dat_dt3[FIRE_NUMBER!="G80051",]
fire_dat_dt3[283]
fire_dat_dt3<-fire_dat_dt3[FIRE_NUMBER!="G90410",]

fire_dat_dt3$Cluster<-as.factor(fire_dat_dt3$Cluster)
```

Below Im going to try do what Kyle did in params/linkHBS_VRI_Calibration.Rmd. Here he fits a gamma and negative binomial model using gamls to correlate observed wood volume to projected volume. Im going to try the same methods to fit area burned i.e. total area in a fire that was observed to burn at low, medium or high intensity to the perimeter size of the fire. Im also going to test wheterh adding fire regime type helps the fit of this model.
```{r}
model1 <- lm(total_area_ha ~ CURRENT_SIZE, data=fire_dat_dt3)
summary(model1)
area_var <- predict(model1, data =fire_dat_dt3, interval="prediction")
init.data <- cbind(fire_dat_dt3, area_var)

lm_eqn = function(m) {
  l <- list(a = format(as.numeric(coef(m)[1]), digits = 2),
      b = format(as.numeric(coef(m)[2]), digits = 2),
      r2 = format(summary(m)$r.squared, digits = 3))
  eq <- substitute(italic(y) == a + b %.% italic(x)*","~~italic(r)^2~"="~r2,l)
  as.character(as.expression(eq))                 
}

ggplot(init.data , aes(CURRENT_SIZE, total_area_ha)) +
  geom_point() +
  geom_smooth(method='lm', se = TRUE)+
  geom_line(aes(y=lwr), color = "red", linetype = "dashed")+
  geom_line(aes(y=upr), color = "red", linetype = "dashed") +
    geom_abline(intercept =0, slope=1, col ="purple") +
  theme_bw()

#I should play with this a little i.e. figure out what the mean and sd or shape and scale are. 
# hist(fire_dat_dt3$total_area_ha, prob = T, xlim=c(0,10000), breaks=2000)
# curve(dgamma(x, 1.2, 0.0001), add=TRUE, col = 'red')
# curve(dnorm(x, 15138, 19838), add=TRUE)
# curve(dlnorm(x, 8.79, 1.41), add=TRUE, col = 'blue')

```

```{r}
## Fit and compare some models
library(gamlss)
fire_dat<-fire_dat_dt3[, c("total_area_ha", "CURRENT_SIZE", "Cluster", "geom")]
fire_dat<-fire_dat[!is.na(Cluster),]
str(fire_dat)

test.0.gamma <- gamlss(total_area_ha ~ CURRENT_SIZE,
                 sigma.formula = ~ 1,
                 mu.link = "log",
                 sigma.link = "log",
                 family = GA(),
                 data = fire_dat,
                 control = gamlss.control(n.cyc = 2000))
test.0.gamma2 <- gamlss(total_area_ha ~ CURRENT_SIZE+Cluster,
                 sigma.formula = ~ 1,
                 mu.link = "log",
                 sigma.link = "log",
                 family = GA(),
                 data = fire_dat,
                 control = gamlss.control(n.cyc = 2000))

test.0.lognor <- gamlss(total_area_ha ~ CURRENT_SIZE,
                 sigma.formula = ~ 1,
                 mu.link = "log",
                 sigma.link = "log",
                 family = LOGNO(),
                 data = fire_dat,
                 control = gamlss.control(n.cyc = 2000))
test.0.lognor2 <- gamlss(total_area_ha ~ CURRENT_SIZE+Cluster,
                 sigma.formula = ~ 1,
                 mu.link = "log",
                 sigma.link = "log",
                 family = LOGNO(),
                 data = fire_dat,
                 control = gamlss.control(n.cyc = 2000))
AIC(test.0.gamma,test.0.gamma2, test.0.lognor, test.0.lognor2)


test.1.gamma <- gamlss(total_area_ha ~ log(CURRENT_SIZE),
                 sigma.formula = ~ 1,
                 sigma.link = "log",
                 family = GA(),
                 data = fire_dat)
test.1.gamma2 <- gamlss(total_area_ha ~ log(CURRENT_SIZE)+Cluster,
                 sigma.formula = ~ 1,
                 sigma.link = "log",
                 family = GA(),
                 data = fire_dat)

test.1.lognor <- gamlss(total_area_ha ~ log(CURRENT_SIZE),
                 sigma.formula = ~ 1,
                 mu.link = "log",
                 sigma.link = "log",
                 family = LOGNO(),
                 data = fire_dat)
test.1.lognor2 <- gamlss(total_area_ha ~ log(CURRENT_SIZE)+Cluster,
                 sigma.formula = ~ 1,
                 mu.link = "log",
                 sigma.link = "log",
                 family = LOGNO(),
                 data = fire_dat)

test.0.gam.inv <- gamlss(total_area_ha ~ CURRENT_SIZE+Cluster,
                 sigma.formula = ~ 1,
                 mu.link = "inverse",
                 sigma.link = "inverse",
                 family = GA(),
                 data = fire_dat,
                 control = gamlss.control(n.cyc = 2000))


# non of these are great. What about if I let the sigma be a function of the Current size

test.2 <- gamlss(total_area_ha ~ CURRENT_SIZE+Cluster,
                 sigma.formula = ~ CURRENT_SIZE,
                 sigma.link = "log",
                 family = GA(),
                 data = fire_dat,
                 control = gamlss.control(n.cyc = 2000))
wp(test.2)

test.3 <- gamlss(total_area_ha ~ log(CURRENT_SIZE),
                 sigma.formula = ~ log(CURRENT_SIZE)+Cluster,
                 sigma.link = "log",
                 family = GA(),
                 data = fire_dat,
                 control = gamlss.control(n.cyc = 2000))
test.4 <- gamlss(total_area_ha ~ CURRENT_SIZE,
                 sigma.formula = ~ CURRENT_SIZE + Cluster,
                 sigma.link = "log",
                 family = GA(),
                 data = na.omit(fire_dat),
                 control = gamlss.control(n.cyc = 2000))
test.5 <- gamlss(total_area_ha ~ log(CURRENT_SIZE) +Cluster,
                 sigma.formula = ~ log(CURRENT_SIZE)+Cluster,
                 sigma.link = "log",
                 family = GA(),
                 data = na.omit(fire_dat),
                 control = gamlss.control(n.cyc = 2000))

test.6 <- gamlss(total_area_ha ~ log(CURRENT_SIZE) +Cluster,
                 family = IG(),
                 data = na.omit(fire_dat),
                 control = gamlss.control(n.cyc = 2000))


m3<-gamlss(total_area_ha~log(CURRENT_SIZE)+Cluster,data=fire_dat,family=GAF, method=mixed(1,300),
c.crit=0.00001)

wp(test.3)
plot(test.3)
GAIC(test.0.gamma, test.0.gamma2, test.0.lognor, test.1.gamma, test.1.gamma2, test.1.lognor, test.1.lognor2, test.1.gamma.inv, test.0.gam.inv,test.3, test.2, test.4, test.5,m3)
```

# Test for spatial autocorrelation
Below i check that the points are independently distributed in space i.e. that there is no spatial auto corrleation i.e. that im over estimating or under estimating the values and that there is a spatial trend to this estimate. 
```{r}
ind.1<- predictAll(test.3, newdata = fire_dat)
mu<-ind.1$mu
ind.2<-cbind(fire_dat, mu)
ind.2$res<-ind.2$total_area_ha - ind.2$mu
#ind.2<- st_as_sf(ind.2) %>% st_cast("POLYGON")

ind.2$centroids <-st_centroid(st_buffer(st_sfc(ind.2$geom), 0))

coords<-st_coordinates(ind.2$centroids)

#get distances

dists <- as.matrix(dist(coords))
dists.inv <- 1/dists 
diag(dists.inv) <- 0
#dists[1:50, 1:50] # check what they look like - units are in metres

#auto.2$res<-auto.2$res+runif(326, 1, 10000)
library(ape)
Moran.I(ind.2$res, dists.inv)
#The P value is not significant its 0.8 this suggests that we cant reject the null hypothesis i.e. that the points are randomly distributed. Good! This also appears to be true when we plot it. see blow.

xyspatial=SpatialPoints(coords)
porspatial=data.frame(ind.2$res)
spatialdata=SpatialPointsDataFrame(xyspatial,porspatial)

library(gstat)
vario2 <- variogram(ind.2$res~1, spatialdata)
plot(vario2)

bubble(spatialdata, "ind.2.res", col = c("blue", "orange"), main = "Residuals", xlab = "X-coordinates", 
    ylab = "Y-coordinates")
```

#fit independent data to test it
Now Im going to test how well my values are predicted. Ill fit the model to 75% of the data and test it on 25% of the data. 


```{r}
set.seed(222)
ind <- sample(2, nrow(fire_dat), replace = TRUE, prob = c(0.75, 0.25))
train <- fire_dat[ind==1,]
table(train$Cluster)
test <- data.table(fire_dat[ind==2,])
test[, geom:=NULL]

test1<-test[,c("CURRENT_SIZE", "Cluster")]

top_mod <- gamlss(total_area_ha ~ log(CURRENT_SIZE),
                 sigma.formula = ~ log(CURRENT_SIZE) + Cluster,
                 sigma.link = "log",
                 family = GA(),
                 data = train,
                 control = gamlss.control(n.cyc = 2000))

predicted<- predictAll(top_mod, newdata = test)

test$mu <- predicted$mu
test$sigma <- predicted$sigma
test$upper.2 <- with(predicted, qGA(0.95, mu = mu, sigma = sigma))
test$lower.2 <- with(predicted, qGA(0.05, mu = mu, sigma = sigma))
test$upper.1 <- with(predicted, qGA(0.67, mu = mu, sigma = sigma))
test$lower.1 <- with(predicted, qGA(0.33, mu = mu, sigma = sigma))

# Plot it
p.min <-
  ggplot(test, aes(x = CURRENT_SIZE, y = total_area_ha) ) +
  geom_point(alpha=0.4) +
  #facet_wrap(~ ForestQualityClass) +
  xlab(expression(paste("Perimeter size, ha"))) +
  ylab(expression(paste("Observed area burned, ha"))) +
  geom_line(aes(y = mu, x = CURRENT_SIZE), color = 'blue', data = test, lwd = 1) +
  geom_line(aes(y = lower.2, x =  CURRENT_SIZE), linetype = "dashed", color = 'red', data = test) +
  geom_line(aes(y = upper.2 , x =  CURRENT_SIZE), linetype = "dashed", color = 'red', data = test) +
  geom_line(aes(y = lower.1 , x =  CURRENT_SIZE), linetype = "dotted", color = 'blue', data = test) +
  geom_line(aes(y = upper.1 , x =  CURRENT_SIZE), linetype = "dotted", color = 'blue', data = test) +
  geom_abline(intercept =0, slope=1, col ="yellow") +
  facet_wrap(~Cluster) + xlim(0,1000) + ylim(0, 1000)




# now trying with a dummy dataset

CURRENT_SIZE<- rep(seq(100,  1000000, by = 1000), 9)
Cluster<-rep(c(5,7,9,10,11,12,13,14,15), each = 9000)

sim_dat<-data.frame(cbind(CURRENT_SIZE, Cluster))
sim_dat$frt_5 <- ifelse(sim_dat$Cluster == 5, 1, 0)
sim_dat$frt_7 <- ifelse(sim_dat$Cluster == 7, 1, 0)
sim_dat$frt_9 <- ifelse(sim_dat$Cluster == 9, 1, 0)
sim_dat$frt_10 <- ifelse(sim_dat$Cluster == 10, 1, 0)
sim_dat$frt_11 <- ifelse(sim_dat$Cluster == 11, 1, 0)
sim_dat$frt_12 <- ifelse(sim_dat$Cluster == 12, 1, 0)
sim_dat$frt_13 <- ifelse(sim_dat$Cluster == 13, 1, 0)
sim_dat$frt_14 <- ifelse(sim_dat$Cluster == 14, 1, 0)
sim_dat$frt_15 <- ifelse(sim_dat$Cluster == 15, 1, 0)

new.dist.min <- predictAll(top_mod, newdata = sim_dat[,c("CURRENT_SIZE", "Cluster")])
sim_dat$mu <- new.dist.min$mu
sim_dat$sigma <- new.dist.min$sigma
sim_dat$upper.2 <- with(new.dist.min, qGA(0.95, mu = mu, sigma = sigma))
sim_dat$lower.2 <- with(new.dist.min, qGA(0.05, mu = mu, sigma = sigma))
sim_dat$upper.1 <- with(new.dist.min, qGA(0.67, mu = mu, sigma = sigma))
sim_dat$lower.1 <- with(new.dist.min, qGA(0.33, mu = mu, sigma = sigma))


p.min <-
  ggplot(sim_dat, aes(x = CURRENT_SIZE, y = mu) ) +
  geom_point(alpha=0.4) +
  #facet_wrap(~ ForestQualityClass) +
  xlab(expression(paste("Projected Volume Yield ", m^3, ")"))) +
  ylab(expression(paste("Observed Volume Yield ", m^3, ")"))) +
  geom_line(aes(y = mu, x = CURRENT_SIZE), color = 'blue', data = sim_dat, lwd = 1.75) +
  geom_line(aes(y = lower.2, x =CURRENT_SIZE  ), linetype = "dashed", color = 'red', data = sim_dat) +
  geom_line(aes(y = upper.2 , x =  CURRENT_SIZE), linetype = "dashed", color = 'red', data = sim_dat) +
  geom_line(aes(y = lower.1 , x =  CURRENT_SIZE), linetype = "dotted", color = 'blue', data = sim_dat) +
  geom_line(aes(y = upper.1 , x =  CURRENT_SIZE), linetype = "dotted", color = 'blue', data = sim_dat) +
  geom_abline(intercept =0, slope=1, col ="green")+
  ylim(0,200000) + facet_wrap(~Cluster)



sigma=top_mod$sigma.coefficients[1] +
  log(sim_dat$CURRENT_SIZE[1])* top_mod$sigma.coefficients[2] +
  sim_dat$frt_5 * top_mod$sigma.coefficients[3] +
  sim_dat$frt_7 * top_mod$sigma.coefficients[2] +
  sim_dat$frt_9 * top_mod$sigma.coefficients[2] + 
  sim_dat$frt_10 * top_mod$sigma.coefficients[2] +
  sim_dat$frt_11 * top_mod$sigma.coefficients[2] +
  sim_dat$frt_12 * top_mod$sigma.coefficients[2] +
  sim_dat$frt_13 * top_mod$sigma.coefficients[2] +
  sim_dat$frt_14 * top_mod$sigma.coefficients[2] +
  sim_dat$frt_15 * top_mod$sigma.coefficients[2]
  
  
mu = coef(top_mod)[1] + 
  log(sim_dat$CURRENT_SIZE)*coef(top_mod)[2] 

x<-rGA(100, mu=sim_dat$mu[1], sigma=sim_dat$sigma[1])

# ok this seems to work.

hist(x)



```

Double check that how Im get the values off the distribution are correct
```{r}
test1<-test[,c("CURRENT_SIZE", "Cluster")]

top_mod <- gamlss(total_area_ha ~ log(CURRENT_SIZE),
                 sigma.formula = ~ log(CURRENT_SIZE) + Cluster,
                 sigma.link = "log",
                 family = GA(),
                 data = train,
                 control = gamlss.control(n.cyc = 2000))

predicted<- predictAll(top_mod, newdata = test1)

test1$mu <- predicted$mu
test1$sigma <- predicted$sigma
test1$upper.2 <- with(predicted, qGA(0.95, mu = mu, sigma = sigma))
test1$lower.2 <- with(predicted, qGA(0.05, mu = mu, sigma = sigma))
test1$upper.1 <- with(predicted, qGA(0.67, mu = mu, sigma = sigma))
test1$lower.1 <- with(predicted, qGA(0.33, mu = mu, sigma = sigma))

test1[,frt_5:=0][Cluster=="5",frt_5:=1]
test1[,frt_7:=0][Cluster=="7",frt_7:=1]
test1[,frt_9:=0][Cluster=="9",frt_9:=1]
test1[,frt_10:=0][Cluster=="10",frt_10:=1]
test1[,frt_11:=0][Cluster=="11",frt_11:=1]
test1[,frt_12:=0][Cluster=="12",frt_12:=1]
test1[,frt_13:=0][Cluster=="13",frt_13:=1]
test1[,frt_14:=0][Cluster=="14",frt_14:=1]
test1[,frt_15:=0][Cluster=="15",frt_15:=1]


test1[,sigma_test:=exp(top_mod$sigma.coefficients[1] + log(CURRENT_SIZE)* top_mod$sigma.coefficients[2] + frt_5 * top_mod$sigma.coefficients[3] + frt_7 * top_mod$sigma.coefficients[4] + frt_9 * top_mod$sigma.coefficients[5] + frt_10 * top_mod$sigma.coefficients[6] + frt_11 * top_mod$sigma.coefficients[7] + frt_12 * top_mod$sigma.coefficients[8] + frt_13 * top_mod$sigma.coefficients[9] + frt_14 * top_mod$sigma.coefficients[10] + frt_15 * top_mod$sigma.coefficients[11])]
  
  
test1[,mu_test := exp(coef(top_mod)[1] + 
  log(CURRENT_SIZE)*coef(top_mod)[2])]



```


